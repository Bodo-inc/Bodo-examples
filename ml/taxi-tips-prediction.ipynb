{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-ghost",
   "metadata": {},
   "source": [
    "# NYC Yellow Taxi Tips Prediction With Machine Learning in Python\n",
    "\n",
    "This example shows use of regression models to predict taxi tip fractions. \n",
    "Original example can be found [here](https://github.com/saturncloud/workshop-scaling-ml/blob/main/04-large-dataset.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f302f-c922-4942-874e-b0a6787022f2",
   "metadata": {},
   "source": [
    "### Start an IPyParallel cluster (skip if running on Bodo Platform)\n",
    "Run the following code in a cell to start an IPyParallel cluster. 8 cores are used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0050c46a-4484-40f4-9aed-5ebccfb5abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.35engine/s]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "import psutil; n = min(psutil.cpu_count(logical=False), 8)\n",
    "rc = ipp.Cluster(engines='mpi', n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f5e9e-78f1-4be3-940a-3fb2b2132927",
   "metadata": {},
   "source": [
    "### Verifying your setup\n",
    "Run the following code to verify that your IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f73c63c-ce82-4d0c-9ecd-8d8b1cf5ea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello World from rank 3. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Hello World from rank 4. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello World from rank 1. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello World from rank 2. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Hello World from rank 7. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Hello World from rank 5. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Hello World from rank 6. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello World from rank 0. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import bodo\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-asset",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - scikit-learn to build and evaluate regression models\n",
    " - xgboost for xgboost regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "japanese-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bodo\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-director",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weird-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|                                                                                               | 0/8 [00:12<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Reading time:  2.241074000000026\n",
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
       "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
       "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
       "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
       "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.5           1                  N           151           239   \n",
       "1            2.6           1                  N           239           246   \n",
       "2            0.0           1                  N           236           236   \n",
       "3            0.0           1                  N           193           193   \n",
       "4            0.0           2                  N           193           193   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          7.0    0.5      0.5        1.65           0.0   \n",
       "1             1         14.0    0.5      0.5        1.00           0.0   \n",
       "2             1          4.5    0.5      0.5        0.00           0.0   \n",
       "3             2          3.5    0.5      0.5        0.00           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          9.95                   NaN  \n",
       "1                    0.3         16.30                   NaN  \n",
       "2                    0.3          5.80                   NaN  \n",
       "3                    0.3          7.55                   NaN  \n",
       "4                    0.3         55.55                   NaN  \n",
       "(10000, 18)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|███████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.61s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def get_taxi_trips():\n",
    "    start = time.time()\n",
    "    taxi = pd.read_csv(\n",
    "        \"s3://bodo-example-data/nyc-taxi/yellow_tripdata_2019.csv\",\n",
    "        parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], nrows=10000\n",
    "    )\n",
    "    print(\"Reading time: \", time.time() - start)\n",
    "    print(taxi.head())\n",
    "    print(taxi.shape)\n",
    "    return taxi\n",
    "    \n",
    "taxi = get_taxi_trips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-tsunami",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-cherry",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "1. Create features before performing any data splitting.\n",
    "2. Split data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suited-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|                                                                                               | 0/8 [00:13<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Data preparation time:  0.0019850000001042645\n",
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "0             1.0                1.0          0.0              24.0   \n",
       "1             1.0                1.0          0.0              24.0   \n",
       "2             4.0               51.0         13.0             109.0   \n",
       "3             2.0               48.0         15.0              63.0   \n",
       "4             2.0               48.0         15.0              63.0   \n",
       "\n",
       "   pickup_minute  passenger_count  tip_fraction  \n",
       "0           46.0              1.0      0.235714  \n",
       "1           59.0              1.0      0.071429  \n",
       "2           48.0              3.0      0.000000  \n",
       "3           52.0              5.0      0.000000  \n",
       "4           56.0              5.0      0.000000  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|███████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:13<00:00,  1.73s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    start = time.time()    \n",
    "    df = taxi_df[taxi_df.fare_amount > 0]['tpep_pickup_datetime', 'passenger_count', 'tip_amount', 'fare_amount'].copy()  # avoid divide-by-zero\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df['pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count', 'tip_fraction'].astype(float).fillna(-1)\n",
    "    print(\"Data preparation time: \", time.time() - start)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "taxi_feat = prep_df(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bottom-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|███████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.56tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit\n",
    "def data_split(taxi_feat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        taxi_feat['pickup_weekday', \n",
    "                    'pickup_weekofyear', \n",
    "                    'pickup_hour', \n",
    "                    'pickup_week_hour', \n",
    "                    'pickup_minute', \n",
    "                    'passenger_count'], \n",
    "        taxi_feat['tip_fraction'], \n",
    "        test_size=0.3,\n",
    "        train_size=0.7,        \n",
    "        random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(taxi_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-surprise",
   "metadata": {},
   "source": [
    "## Train Model over large dataset\n",
    "\n",
    "We'll train a linear model to predict tip_fraction and evaluate these models against the test set using RMSE.\n",
    "\n",
    "#### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rocky-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|                                                                                               | 0/8 [00:00<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Linear Regression fitting time:  0.10938899999996465\n",
       "Linear Regression prediction time:  0.002658999999994194\n",
       "775437450.3689747\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|███████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.73tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def lr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    lr = LinearRegression()\n",
    "    lr_fitted = lr.fit(X_train, y_train)\n",
    "    print(\"Linear Regression fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    lr_preds = lr_fitted.predict(X_test)\n",
    "    print(\"Linear Regression prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, lr_preds, squared=False))\n",
    "    \n",
    "lr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-julian",
   "metadata": {},
   "source": [
    "#### 2. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collaborative-prison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Ridge fitting time:  0.11805099999992308\n",
       "Ridge prediction time:  0.0017510000000129367\n",
       "246173655470.98502\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit\n",
    "def rr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    rr = Ridge()\n",
    "    rr_fitted = rr.fit(X_train, y_train)\n",
    "    print(\"Ridge fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    rr_preds = rr_fitted.predict(X_test)\n",
    "    print(\"Ridge prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, rr_preds, squared=False))\n",
    "    \n",
    "rr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-session",
   "metadata": {},
   "source": [
    "#### 3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "executed-winning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Lasso fitting time:  0.10019899999997506\n",
       "Lasso prediction time:  0.0018880000000081054\n",
       "59969897832.56497\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit\n",
    "def lsr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    lsr = Lasso()\n",
    "    lsr_fitted = lsr.fit(X_train, y_train)\n",
    "    print(\"Lasso fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    lsr_preds = lsr_fitted.predict(X_test)\n",
    "    print(\"Lasso prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, lsr_preds, squared=False))\n",
    "    \n",
    "lsr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-evolution",
   "metadata": {},
   "source": [
    "#### 4. SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "related-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] SGDRegressor fitting time:  0.20479599999998754\n",
       "SGDRegressor prediction time:  0.003669000000172673\n",
       "494260382.85129654\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit\n",
    "def sgdr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    sgdr = SGDRegressor(max_iter=100, penalty='l2')\n",
    "    sgdr_fitted = sgdr.fit(X_train, y_train)\n",
    "    print(\"SGDRegressor fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    sgdr_preds = sgdr_fitted.predict(X_test)\n",
    "    print(\"SGDRegressor prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, sgdr_preds, squared=False))\n",
    "    \n",
    "sgdr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-correspondence",
   "metadata": {},
   "source": [
    "#### 5. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hispanic-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] XGBRegressor fitting time:  0.04732899999999063\n",
       "XGBRegressor prediction time:  0.005711999999903128\n",
       "0.22680806722334323\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def xgb_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method='approx',\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "    )\n",
    "    xgb_fitted = xgb.fit(X_train, y_train)\n",
    "    print(\"XGBRegressor fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    xgb_preds = xgb_fitted.predict(X_test)\n",
    "    print(\"XGBRegressor prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, xgb_preds, squared=False))\n",
    "    \n",
    "xgb_model(X_train, y_train, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conditional-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping controller\n",
      "Controller stopped: {'exit_code': 0, 'pid': 21481, 'identifier': 'ipcontroller-1653095920-59jm-21470'}\n",
      "Stopping engine(s): 1653095921\n",
      "mpiexec error output:\n",
      "===================================================================================\n",
      "=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n",
      "=   PID 21495 RUNNING AT nicholass-mbp.lan\n",
      "=   EXIT CODE: 9\n",
      "=   CLEANING UP REMAINING PROCESSES\n",
      "=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n",
      "===================================================================================\n",
      "YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Segmentation fault: 11 (signal 11)\n",
      "\n",
      "engine set stopped 1653095921: {'exit_code': 11, 'pid': 21493, 'identifier': 'ipengine-1653095920-59jm-1653095921-21470'}\n"
     ]
    }
   ],
   "source": [
    "# To stop the cluster run the following command. \n",
    "rc.cluster.stop_cluster_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9f47c-b8b5-43b3-b78b-2d855afaafb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16c8ad1c156570dbb9b8c59e261dba05f4270231d6ef51b3fb205099379bfe9f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
