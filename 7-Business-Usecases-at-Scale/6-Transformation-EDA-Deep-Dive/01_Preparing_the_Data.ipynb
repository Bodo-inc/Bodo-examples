{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962a91dd-0003-454a-877b-628ffa138580",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d43bf-1ef3-4b76-8d80-5140e24491af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Warning:</b>\n",
    "Executing this initial notebook is likely to crash your Jupyter kernel on a system with less than 16GB physical RAM—the basic calls to Pandas's `read_csv` function alone will use up nearly all the available memory. In that case, you can use the <a href=\"https://www.bodo.ai/try-bodo\">Bodo cloud platform</a> for free, or just read the notebook without attempting to execute cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb682c8-43d2-47b6-96f3-3e9a8449ff73",
   "metadata": {},
   "source": [
    "This series of notebooks is inspired by Jonah Blumstein's [NYC Parking Violations Mapping Example](https://github.com/JBlumstein/NYCParking/blob/master/NYC_Parking_Violations_Mapping_Example.ipynb).\n",
    "\n",
    "The data used comes from NYC parking tickets issued during the years 2016 and 2017. The original CSV files are available in an S3 bucket (`s3://bodo-examples-data/nyc-parking-tickets`). You can alternatively get the data from [Kaggle](https://www.kaggle.com/new-york-city/nyc-parking-tickets) (data for other years are also available, but may not run through the analysis here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de589d40",
   "metadata": {},
   "source": [
    "In our code, we would very much like to have a function that looks something like the following:\n",
    "\n",
    "```python\n",
    "def load_parking_tickets():\n",
    "    groupby_cols = ['Issue Date','Violation County','Violation Precinct','Violation Code']\n",
    "    DATA_SRC = 'ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2016.csv'\n",
    "    df = pd.read_csv(DATA_SRC, parse_dates=[\"Issue Date\"])\n",
    "    df = df.groupby(groupby_cols, as_index=False)['Summons Number'].count()\n",
    "    return df\n",
    "```\n",
    "\n",
    "Even assuming the data is stored locally in the directory `ParkingData`, you encounter a few warnings on execution:\n",
    "- First, mixed data types (those `NaN`s get you every time).\n",
    "- Second, this will eat up a lot of physical memory; yes, you might happen to have a machine/cluster that handles it cleanly, but that might not always be the case with other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca04c4-4314-459c-a235-a1a742c8193e",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643ea0f",
   "metadata": {},
   "source": [
    "## Examining a chunk of the 2016 data\n",
    "Let's take a quick look at what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e44612-288c-486b-b591-30c476da2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some relevant packages\n",
    "import pandas as pd\n",
    "from s3fs import S3FileSystem\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef548ba8-cee7-41f3-ba7b-4fc6fca6205e",
   "metadata": {
    "tags": []
   },
   "source": [
    "The data is available remotely on an S3 bucket. It will be more convenient to work from local files. The code in the following cell will download two large CSV files from the S3 bucket (unless the files have already been downloaded).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Warning:</b>\n",
    "<ul>\n",
    "    <li> Downloading this data could take some time (depending on your network speed).</li>\n",
    "    <li> The \"test\" <tt>not local_file.exists()</tt> is easily fooled (for instance, by an empty file in the same location). In particular, there is no attempt made to verify the integrity of the data downloaded (e.g., by verifying a hash or some similar method).</li>\n",
    "</ul>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c376deba-a48b-460a-b02a-e32218f7bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure files are downloaded\n",
    "s3 = S3FileSystem(anon=True)\n",
    "S3_PATH = 'bodo-example-data/nyc-parking-tickets'\n",
    "LOCAL_PATH = pathlib.Path('.') / 'ParkingData'\n",
    "FNAME_TMPL = 'Parking_Violations_Issued_-_Fiscal_Year_{}.csv'\n",
    "years = range(2016, 2018)\n",
    "\n",
    "for yr in years:\n",
    "    fname = FNAME_TMPL.format(yr)\n",
    "    local_file = LOCAL_PATH / fname\n",
    "    remote_file = f'{S3_PATH}/{fname}'\n",
    "    if not local_file.exists():\n",
    "        # Checks only filename, not contents/type!\n",
    "        s3.get(rpath=remote_file, lpath=str(local_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa0f1b-7918-436e-9211-1647c399ec0e",
   "metadata": {},
   "source": [
    "These CSV files each contain almost 11 million rows. On a Unix-based system, the `wc` command shows the file line counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84c8c44-f6dc-4564-a212-e9a007413d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10626900 ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\n",
      "  10803029 ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\n",
      "  21429929 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l ParkingData/Parking_Violations_Issued_*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9813e3-a2ac-44af-a8e8-ee2fc118840d",
   "metadata": {},
   "source": [
    "The preceding shell command, if it executes on your operating system, produces output like this\n",
    "```bash\n",
    "  10626900 ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\n",
    "  10803029 ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\n",
    "  21429929 total\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8280db-9ff8-4150-8d5f-546d36e97247",
   "metadata": {},
   "source": [
    "To get a better sense of the data, let's read the first million rows from the file for 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe963829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/daruliah@quansight.com/8055a4a1a475fa85432dbb254ad61ae4f9fdddf7460037cb3704295231c42695-20220429-030957-213968-10-Bodo/lib/python3.9/site-packages/IPython/core/magics/execution.py:1316: DtypeWarning: Columns (17,18,20,21,22,23,29,30,31,32,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code, glob, local_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 301 ms, total: 2.99 s\n",
      "Wall time: 3.01 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summons Number</th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Registration State</th>\n",
       "      <th>Plate Type</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Violation Code</th>\n",
       "      <th>Vehicle Body Type</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Issuing Agency</th>\n",
       "      <th>Street Code1</th>\n",
       "      <th>...</th>\n",
       "      <th>Hydrant Violation</th>\n",
       "      <th>Double Parking Violation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Community Council</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>BBL</th>\n",
       "      <th>NTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363745270</td>\n",
       "      <td>GGY6450</td>\n",
       "      <td>99</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>46</td>\n",
       "      <td>SDN</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1363745293</td>\n",
       "      <td>KXD355</td>\n",
       "      <td>SC</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>21</td>\n",
       "      <td>SUBN</td>\n",
       "      <td>CHEVR</td>\n",
       "      <td>P</td>\n",
       "      <td>55730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363745438</td>\n",
       "      <td>JCK7576</td>\n",
       "      <td>PA</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>21</td>\n",
       "      <td>SDN</td>\n",
       "      <td>ME/BE</td>\n",
       "      <td>P</td>\n",
       "      <td>42730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1363745475</td>\n",
       "      <td>GYK7658</td>\n",
       "      <td>NY</td>\n",
       "      <td>OMS</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>21</td>\n",
       "      <td>SUBN</td>\n",
       "      <td>NISSA</td>\n",
       "      <td>P</td>\n",
       "      <td>58130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1363745487</td>\n",
       "      <td>GMT8141</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>21</td>\n",
       "      <td>P-U</td>\n",
       "      <td>LINCO</td>\n",
       "      <td>P</td>\n",
       "      <td>58130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Summons Number Plate ID Registration State Plate Type Issue Date  \\\n",
       "0      1363745270  GGY6450                 99        PAS 2015-07-09   \n",
       "1      1363745293   KXD355                 SC        PAS 2015-07-09   \n",
       "2      1363745438  JCK7576                 PA        PAS 2015-07-09   \n",
       "3      1363745475  GYK7658                 NY        OMS 2015-07-09   \n",
       "4      1363745487  GMT8141                 NY        PAS 2015-07-09   \n",
       "\n",
       "   Violation Code Vehicle Body Type Vehicle Make Issuing Agency  Street Code1  \\\n",
       "0              46               SDN        HONDA              P             0   \n",
       "1              21              SUBN        CHEVR              P         55730   \n",
       "2              21               SDN        ME/BE              P         42730   \n",
       "3              21              SUBN        NISSA              P         58130   \n",
       "4              21               P-U        LINCO              P         58130   \n",
       "\n",
       "   ...  Hydrant Violation  Double Parking Violation  Latitude  Longitude  \\\n",
       "0  ...                NaN                       NaN       NaN        NaN   \n",
       "1  ...                NaN                       NaN       NaN        NaN   \n",
       "2  ...                NaN                       NaN       NaN        NaN   \n",
       "3  ...                NaN                       NaN       NaN        NaN   \n",
       "4  ...                NaN                       NaN       NaN        NaN   \n",
       "\n",
       "   Community Board  Community Council   Census Tract BIN BBL NTA  \n",
       "0              NaN                 NaN           NaN NaN NaN NaN  \n",
       "1              NaN                 NaN           NaN NaN NaN NaN  \n",
       "2              NaN                 NaN           NaN NaN NaN NaN  \n",
       "3              NaN                 NaN           NaN NaN NaN NaN  \n",
       "4              NaN                 NaN           NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine a chunk from local source\n",
    "fname = FNAME_TMPL.format(2016)\n",
    "DATA_SRC = LOCAL_PATH / fname\n",
    "%time df_chunk = pd.read_csv(DATA_SRC, parse_dates=[\"Issue Date\"], nrows=1_000_000 )\n",
    "display(df_chunk.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353320b-0c5f-4f71-8d78-29ccd53f83b5",
   "metadata": {},
   "source": [
    "On reading the data, we'll see a warning that resembles this:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<tt>DtypeWarning: Columns (17,18,20,21,22,23,29,30,31,32,34,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.</tt>\n",
    "</div>\n",
    "\n",
    "This tells us that some columns are being parsed using mixed data-types—with an accompanying memory penalty. Let's see which columns these correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5fc510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issuer Command', 'Issuer Squad', 'Time First Observed',\n",
       "       'Violation County', 'Violation In Front Of Or Opposite', 'House Number',\n",
       "       'Violation Legal Code', 'Days Parking In Effect    ',\n",
       "       'From Hours In Effect', 'To Hours In Effect', 'Unregistered Vehicle?',\n",
       "       'Meter Number', 'Violation Post Code', 'Violation Description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk.columns[[17,18,20,21,22,23,29,30,31,32,34,36,38,39]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d47e80-795a-4875-ab46-cdaeefdd8270",
   "metadata": {},
   "source": [
    "A simple solution may be to cast those columns as strings on read with the `dtype` option to `pd.read_csv` and then clean things up later. However, we want to explore a bit first to see what is used otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889eda61-0de0-4cc8-b2f6-3a66cbe61666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 51 columns):\n",
      " #   Column                             Non-Null Count    Dtype         \n",
      "---  ------                             --------------    -----         \n",
      " 0   Summons Number                     1000000 non-null  int64         \n",
      " 1   Plate ID                           999785 non-null   object        \n",
      " 2   Registration State                 1000000 non-null  object        \n",
      " 3   Plate Type                         1000000 non-null  object        \n",
      " 4   Issue Date                         1000000 non-null  datetime64[ns]\n",
      " 5   Violation Code                     1000000 non-null  int64         \n",
      " 6   Vehicle Body Type                  996603 non-null   object        \n",
      " 7   Vehicle Make                       994287 non-null   object        \n",
      " 8   Issuing Agency                     1000000 non-null  object        \n",
      " 9   Street Code1                       1000000 non-null  int64         \n",
      " 10  Street Code2                       1000000 non-null  int64         \n",
      " 11  Street Code3                       1000000 non-null  int64         \n",
      " 12  Vehicle Expiration Date            1000000 non-null  int64         \n",
      " 13  Violation Location                 865801 non-null   float64       \n",
      " 14  Violation Precinct                 1000000 non-null  int64         \n",
      " 15  Issuer Precinct                    1000000 non-null  int64         \n",
      " 16  Issuer Code                        1000000 non-null  int64         \n",
      " 17  Issuer Command                     866795 non-null   object        \n",
      " 18  Issuer Squad                       866666 non-null   object        \n",
      " 19  Violation Time                     996397 non-null   object        \n",
      " 20  Time First Observed                103077 non-null   object        \n",
      " 21  Violation County                   859333 non-null   object        \n",
      " 22  Violation In Front Of Or Opposite  856278 non-null   object        \n",
      " 23  House Number                       846791 non-null   object        \n",
      " 24  Street Name                        995997 non-null   object        \n",
      " 25  Intersecting Street                261302 non-null   object        \n",
      " 26  Date First Observed                1000000 non-null  int64         \n",
      " 27  Law Section                        1000000 non-null  int64         \n",
      " 28  Sub Division                       996457 non-null   object        \n",
      " 29  Violation Legal Code               133275 non-null   object        \n",
      " 30  Days Parking In Effect             764351 non-null   object        \n",
      " 31  From Hours In Effect               556796 non-null   object        \n",
      " 32  To Hours In Effect                 556796 non-null   object        \n",
      " 33  Vehicle Color                      986191 non-null   object        \n",
      " 34  Unregistered Vehicle?              105795 non-null   float64       \n",
      " 35  Vehicle Year                       1000000 non-null  int64         \n",
      " 36  Meter Number                       178412 non-null   object        \n",
      " 37  Feet From Curb                     1000000 non-null  int64         \n",
      " 38  Violation Post Code                757659 non-null   object        \n",
      " 39  Violation Description              890712 non-null   object        \n",
      " 40  No Standing or Stopping Violation  0 non-null        float64       \n",
      " 41  Hydrant Violation                  0 non-null        float64       \n",
      " 42  Double Parking Violation           0 non-null        float64       \n",
      " 43  Latitude                           0 non-null        float64       \n",
      " 44  Longitude                          0 non-null        float64       \n",
      " 45  Community Board                    0 non-null        float64       \n",
      " 46  Community Council                  0 non-null        float64       \n",
      " 47  Census Tract                       0 non-null        float64       \n",
      " 48  BIN                                0 non-null        float64       \n",
      " 49  BBL                                0 non-null        float64       \n",
      " 50  NTA                                0 non-null        float64       \n",
      "dtypes: datetime64[ns](1), float64(13), int64(13), object(24)\n",
      "memory usage: 389.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_chunk.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d69afa-bbaa-408c-95b4-dc2d9433f119",
   "metadata": {},
   "source": [
    "The columns are mostly strings (represented as `object` in the output to `df_chunk.info()`). The `Issue Date` column is of dtype `datetime64` (as specified in the call to `read_csv`) and the remaining columns are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51266262-0d2f-42bc-9095-a49a68809d0a",
   "metadata": {},
   "source": [
    "Looking at a few of the offending mixed-dtype columns, we can see that they are mostly strings. We can use the `DataFrame.unique` method to get a sense of how many distinct entries there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc87d9f-1186-4ba5-9a48-990971243668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['K', nan, 'Q', 'NY', 'BX', 'R', 'QU', 'KINGS'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many distinct entries are there in the 'Violation County' column?\n",
    "df_chunk['Violation County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfb812b-f94a-4ca3-86e9-af033da3c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, nan, 'J', 'D', '0000', 'O', 'H', 'U', 'E', 'B', 'R', 'G', 'F',\n",
       "       'T', 'S', 'A', 'Q', 'P', 'M', 'L', 'N', 'I', 'C', 'K', 'X', 'V',\n",
       "       'X1', 'CC', 'Y', 'E1', 'B2', 'GP', 'A2', 'AA', 'A1', 'B1', 'X2',\n",
       "       'D1', 'YA'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many distinct entries are there in the 'Issuer Squad' column?\n",
    "df_chunk['Issuer Squad'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f158f468-5626-4cfe-a145-b0a3a9ebed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'O', nan, 'I', 'R', 'X'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many distinct entries are there in the 'Violation In Front Of Or Opposite' column?\n",
    "df_chunk['Violation In Front Of Or Opposite'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b7723",
   "metadata": {},
   "source": [
    "These columns are in fact largely *categorical* (in having relatively few distinct strings). Moreover, any missing entries are interpreted as `numpy.nan`. There are also some instances of strings like `'0'` being parsed as the integer `0` which also contributes to the \"mixed dtype\" warning (which suggests that the first row in the CSV file has a numeric string in that column, giving the misleading impression that the entire column should be all integers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d3a7c-3eb0-4fdc-be76-52834b0f46fc",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d88bb",
   "metadata": {},
   "source": [
    "## Working with the entire data set\n",
    "\n",
    "From this quick look, we might decide to cast the NaNs in `'Violation County'` as strings explicitly and handle other columns later. Another alternative is to use the `read_csv` option `'usecols'`.\n",
    "\n",
    "```python\n",
    "def load_parking_tickets():\n",
    "    groupby_cols = ['Issue Date','Violation County','Violation Precinct','Violation Code']\n",
    "    DATA_SRC = 'ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2016.csv'\n",
    "    df = pd.read_csv(DATA_SRC, parse_dates=[\"Issue Date\"])\n",
    "    df['Violation County'] = df['Violation County'].fillna('NAN')\n",
    "    df = df.groupby(groupby_cols, as_index=False)['Summons Number'].count()\n",
    "    return df\n",
    "```\n",
    "\n",
    "Let's now load the entire file of about 11 million rows into memory (if possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa035c3a-149c-47e0-bf0f-adbd665a4400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/daruliah@quansight.com/8055a4a1a475fa85432dbb254ad61ae4f9fdddf7460037cb3704295231c42695-20220429-030957-213968-10-Bodo/lib/python3.9/site-packages/IPython/core/magics/execution.py:1316: DtypeWarning: Columns (17,18,20,21,22,23,29,30,31,32,34,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code, glob, local_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 s, sys: 6.7 s, total: 37.3 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%time year_2016_df = pd.read_csv(DATA_SRC, parse_dates=[\"Issue Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf9fad-5293-4d7e-b8e6-6c4682e361ad",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7f5fa-a148-4784-97d5-11b908d8dc8c",
   "metadata": {},
   "source": [
    "## Working with Parquet files\n",
    "\n",
    "The strategies above address the issue of parsing columns from a CSV file as mixed dtypes; if we're stuck with no choice but to use CSV files, so be it. But another option is available: re-encoding the data as *Parquet* files. This has a number of advantages, but encoding the data as a Parquet file does require being explicit about the column data types. To resolve the matter of a few columns being parsed as a mixture of data types, we can force those columns to parse as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14678b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2016_df['Summons Number'] = year_2016_df['Summons Number'].astype(str) # This identifier\n",
    "year_2016_df['Violation County'] = year_2016_df['Violation County'].astype(str)\n",
    "year_2016_df['House Number'] = year_2016_df['House Number'].astype(str)\n",
    "year_2016_df['Issuer Squad'] = year_2016_df['Issuer Squad'].astype(str)\n",
    "year_2016_df['Unregistered Vehicle?'] = year_2016_df['Unregistered Vehicle?'].astype(str)\n",
    "year_2016_df['Violation Post Code'] = year_2016_df['Violation Post Code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338e5f6-2a87-48ed-ac83-16c3df2820b3",
   "metadata": {},
   "source": [
    "We can now encode the dataframe as a Parquet file using the `DataFrame.to_parquet` method. Actually, we'll do it twice: once without using any keyword options and the second time using the `row_group_size` option to segment the resulting Parquet file (more on this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029882bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TARGET = LOCAL_PATH / 'Parking_Violations_Issued_-_Fiscal_Year_2016.parquet'\n",
    "if not DATA_TARGET.exists():\n",
    "    year_2016_df.to_parquet(DATA_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7b8b1c-9b2a-4a51-bf10-470613a7b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TARGET = LOCAL_PATH / 'Parking_Violations_Issued_-_Fiscal_Year_2016_segmented.parquet'\n",
    "if not DATA_TARGET.exists():\n",
    "    year_2016_df.to_parquet(DATA_TARGET, row_group_size=100_000, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90264b-7750-4f8b-9bbf-f1615dc62acb",
   "metadata": {},
   "source": [
    "There are a number of advantages to using PArquet files. First of all, Parquet encoding comes with considerable space savings. This data required ~2 GB when stored as a CSV file; as Parquet files—with the same data, and even dtypes to boot—the storage needed is about 380 MB.\n",
    "\n",
    "And then there's how the data is read in: Parquet files are *column-oriented* (rather than row-oriented like CSV files). So reading in a selected subset of columns from Parquet is very efficient (saving both time and RAM overhead). By contrast, for CSV files, you need to read through the entire file... and wait for each row to be parsed to extract the required columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0c343-d52c-4b2d-94a2-47ff4443bd4d",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee5f7e",
   "metadata": {},
   "source": [
    "## Repeating for the 2017 data\n",
    "\n",
    "If you have the memory to do so, you can just do the same again for 2017, otherwise you'll likely need to restart your kernel and skip all the 2016 data, before repeating the write for 2017. Notice there are slightly different columns yielding mixed-dtype warning messages for this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f57a1fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/daruliah@quansight.com/8055a4a1a475fa85432dbb254ad61ae4f9fdddf7460037cb3704295231c42695-20220429-030957-213968-10-Bodo/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3369: DtypeWarning: Columns (18,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_SRC = 'ParkingData/Parking_Violations_Issued_-_Fiscal_Year_2017.csv'\n",
    "year_2017_df = pd.read_csv(DATA_SRC, parse_dates=[\"Issue Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "379f6312-909a-43de-ad88-d6af9e3c6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2017_df['Summons Number'] = year_2017_df['Summons Number'].astype(str) # This identifier\n",
    "year_2017_df['Violation County'] = year_2017_df['Violation County'].astype(str)\n",
    "year_2017_df['House Number'] = year_2017_df['House Number'].astype(str)\n",
    "year_2017_df['Issuer Squad'] = year_2017_df['Issuer Squad'].astype(str)\n",
    "year_2017_df['Unregistered Vehicle?'] = year_2017_df['Unregistered Vehicle?'].astype(str)\n",
    "year_2017_df['Violation Post Code'] = year_2017_df['Violation Post Code'].astype(str)\n",
    "year_2017_df['Issuer Squad'] = year_2017_df['Issuer Squad'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cde7e72-8583-4157-9b65-3e305d61006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TARGET = LOCAL_PATH / 'Parking_Violations_Issued_-_Fiscal_Year_2017.parquet'\n",
    "if not DATA_TARGET.exists():\n",
    "    year_2017_df.to_parquet(DATA_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c9db80-a424-4332-97f6-e3fa1025a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TARGET = LOCAL_PATH / 'Parking_Violations_Issued_-_Fiscal_Year_2017_segmented.parquet'\n",
    "if not DATA_TARGET.exists():\n",
    "    year_2017_df.to_parquet(DATA_TARGET, row_group_size=100_000, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5ace6",
   "metadata": {},
   "source": [
    "Now we have the data encoded as CSV, Parquet, and segmented Parquet files—in the next notebook we'll take a look at what that gets us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c8f0a-79f7-4291-939b-c3daf7225dd1",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daruliah@quansight.com-Bodo",
   "language": "python",
   "name": "conda-env-daruliah_quansight.com-Bodo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
