{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example analyzes beer reviews to find the most common words used in positive and negative reviews.\n",
    "Original example can be found [here](https://medium.com/rapids-ai/real-data-has-strings-now-so-do-gpus-994497d55f8e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on running these queries:\n",
    "\n",
    "By defaults runs use Bodo. Hence, data is distributed in chunks across processes.\n",
    "\n",
    "The current results are based on running on one **m5.8xlarge** instance (16 cores, 128GiB memory)\n",
    "\n",
    "reviews_sample.csv size is 23.1MB\n",
    "\n",
    "Fulldataset is available on \"s3://bodo-examples-data/beer/reviews.csv\" and its size is 2.2GB\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you add your AWS account credentials to access the data. \n",
    "2. If you want to run the example using pandas only (without Bodo):\n",
    "    1. Comment lines magic expression (`%%px`) and bodo decorator (`@bodo.jit`) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import json\n",
    "import os\n",
    "\n",
    "path_to_conn_creds = \"credentials.json\"\n",
    "with open(path_to_conn_creds) as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = creds[\"aws\"][\"aws_access_key_id\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = creds[\"aws\"][\"aws_secret_access_key\"]\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import bodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. Create lists of stopwords and punctuation that will be removed.\n",
    "2. Define regex that will be used to remove these punctuation and stopwords from the reviews.\n",
    "3. Use the lower and strip functions to convert all letters to lowercase and remove excess whitespace. \n",
    "4. Remove stopwords and punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "with open(\"nltk-stopwords.txt\", \"r\") as fh:\n",
    "    STOPWORDS = list(map(str.strip, fh.readlines()))\n",
    "\n",
    "\n",
    "PUNCT_LIST = [\"\\.\", \"\\-\", \"\\?\", \"\\:\", \":\", \"!\", \"&\", \"'\", \",\"]\n",
    "punc_regex = \"|\".join([f\"({p})\" for p in PUNCT_LIST])\n",
    "stopword_regex = \"|\".join([f\"\\\\b({s})\\\\b\" for s in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"reviews\"])\n",
    "def preprocess(reviews):\n",
    "    # lowercase and strip\n",
    "    reviews = reviews.str.lower()\n",
    "    reviews = reviews.str.strip()\n",
    "\n",
    "    # remove punctuation and stopwords\n",
    "    reviews = reviews.str.replace(punc_regex, \"\", regex=True)\n",
    "    reviews = reviews.str.replace(stopword_regex, \"\", regex=True)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "BodoWarning: Unable to get S3 Bucket Region.\n",
      "'coroutine' object is not subscriptable.\n",
      "Will use the value defined in the AWS_DEFAULT_REGION environment variable (or us-east-1 if that is not provided either).\n",
      "read time 0.8933188915252686\n",
      "preprocess time 6.139484882354736\n",
      "high/low time 0.0021250247955322266\n",
      "value_counts time 0.006670951843261719\n",
      "total time 7.042609930038452\n",
      "beer         333\n",
      "one          158\n",
      "taste        140\n",
      "head         119\n",
      "like         117\n",
      "best         102\n",
      "chocolate     90\n",
      "dark          90\n",
      "great         86\n",
      "perfect       80\n",
      "good          79\n",
      "sweet         77\n",
      "smell         73\n",
      "bottle        72\n",
      "ive           70\n",
      "flavor        68\n",
      "glass         65\n",
      "well          65\n",
      "ever          65\n",
      "aroma         64\n",
      "nice          64\n",
      "malt          63\n",
      "bourbon       62\n",
      "hops          62\n",
      "beers         62\n",
      "dtype: int64\n",
      "beer           239\n",
      "like           109\n",
      "taste          104\n",
      "head            69\n",
      "light           65\n",
      "one             65\n",
      "smell           57\n",
      "bad             53\n",
      "bottle          52\n",
      "really          49\n",
      "good            41\n",
      "would           40\n",
      "get             38\n",
      "water           35\n",
      "flavor          33\n",
      "much            32\n",
      "carbonation     32\n",
      "smells          32\n",
      "beers           32\n",
      "corn            31\n",
      "glass           31\n",
      "even            31\n",
      "poured          30\n",
      "tastes          29\n",
      "drink           29\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit\n",
    "def find_top_words(review_filename):\n",
    "    # Load in the data\n",
    "    t_start = time.time()\n",
    "    df = pd.read_csv(review_filename, parse_dates=[2])\n",
    "    print(\"read time\", time.time() - t_start)\n",
    "\n",
    "    score = df.score\n",
    "    reviews = df.text\n",
    "\n",
    "    t1 = time.time()\n",
    "    reviews = preprocess(reviews)\n",
    "    print(\"preprocess time\", time.time() - t1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    # create low and high score series\n",
    "    low_threshold = 1.5\n",
    "    high_threshold = 4.95\n",
    "    high_reviews = reviews[score > high_threshold]\n",
    "    low_reviews = reviews[score <= low_threshold]\n",
    "    high_reviews = high_reviews.dropna()\n",
    "    low_reviews = low_reviews.dropna()\n",
    "\n",
    "    high_colsplit = high_reviews.str.split()\n",
    "    low_colsplit = low_reviews.str.split()\n",
    "    print(\"high/low time\", time.time() - t1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    high_words = high_colsplit.explode()\n",
    "    low_words = low_colsplit.explode()\n",
    "\n",
    "    top_words = high_words.value_counts().head(25)\n",
    "    low_words = low_words.value_counts().head(25)\n",
    "    print(\"value_counts time\", time.time() - t1)\n",
    "    print(\"total time\", time.time() - t_start)\n",
    "\n",
    "    print(top_words)\n",
    "    print(low_words)\n",
    "    \n",
    "find_top_words(\"s3://bodo-examples-data/beer/reviews_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
