{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TPC-H Queries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TPC-H queries implemented in Spark using PySpark SQL\n",
    "\n",
    "Tested under Spark 3.1.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import required Packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Datasets Methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_lineitem(data_folder, spark):\n",
    "    lineitem = spark.read.parquet(\n",
    "        data_folder + \"/lineitem.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    lineitem.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(lineitem.count())\n",
    "    # Add for Spark SQL\n",
    "    lineitem.createOrReplaceTempView(\"lineitem\")\n",
    "\n",
    "\n",
    "def load_part(data_folder, spark):\n",
    "    part = spark.read.parquet(\n",
    "        data_folder + \"/part.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    part.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(part.count())\n",
    "    # Add for Spark SQL\n",
    "    part.createOrReplaceTempView(\"part\")\n",
    "\n",
    "\n",
    "def load_orders(data_folder, spark):\n",
    "    orders = spark.read.parquet(\n",
    "        data_folder + \"/orders.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    orders.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(orders.count())\n",
    "    # Add for Spark SQL\n",
    "    orders.createOrReplaceTempView(\"orders\")\n",
    "\n",
    "\n",
    "def load_customer(data_folder, spark):\n",
    "    customer = spark.read.parquet(\n",
    "        data_folder + \"/customer.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    customer.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(customer.count())\n",
    "    # Add for Spark SQL\n",
    "    customer.createOrReplaceTempView(\"customer\")\n",
    "\n",
    "\n",
    "def load_nation(data_folder, spark):\n",
    "    nation = spark.read.parquet(\n",
    "        data_folder + \"/nation.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    nation.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(nation.count())\n",
    "    # Add for Spark SQL\n",
    "    nation.createOrReplaceTempView(\"nation\")\n",
    "\n",
    "\n",
    "def load_region(data_folder, spark):\n",
    "    region = spark.read.parquet(\n",
    "        data_folder + \"/region.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    region.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(region.count())\n",
    "    # Add for Spark SQL\n",
    "    region.createOrReplaceTempView(\"region\")\n",
    "\n",
    "\n",
    "def load_supplier(data_folder, spark):\n",
    "    supplier = spark.read.parquet(\n",
    "        data_folder + \"/supplier.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    supplier.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(supplier.count())\n",
    "    # Add for Spark SQL\n",
    "    supplier.createOrReplaceTempView(\"supplier\")\n",
    "\n",
    "\n",
    "def load_partsupp(data_folder, spark):\n",
    "    partsupp = spark.read.parquet(\n",
    "        data_folder + \"/partsupp.pq/\"\n",
    "    )\n",
    "    # Persist to get accurate read times\n",
    "    partsupp.persist(StorageLevel.MEMORY_ONLY)\n",
    "    print(partsupp.count())\n",
    "    # Add for Spark SQL\n",
    "    partsupp.createOrReplaceTempView(\"partsupp\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Queries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def q01(spark):\n",
    "    t1 = time.time()\n",
    "    sql_lineitem = spark.sql(\n",
    "        \"\"\"select\n",
    "                l_returnflag,\n",
    "                l_linestatus,\n",
    "                sum(l_quantity) as sum_qty,\n",
    "                sum(l_extendedprice) as sum_base_price,\n",
    "                sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,\n",
    "                sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,\n",
    "                avg(l_quantity) as avg_qty,\n",
    "                avg(l_extendedprice) as avg_price,\n",
    "                avg(l_discount) as avg_disc,\n",
    "                count(*) as count_order\n",
    "            from\n",
    "                lineitem\n",
    "            where\n",
    "                l_shipdate <= date '1998-12-01' - interval '90' day\n",
    "            group by\n",
    "                l_returnflag,\n",
    "                l_linestatus\n",
    "            order by\n",
    "                l_returnflag,\n",
    "                l_linestatus\"\"\"\n",
    "    )\n",
    "\n",
    "    sql_lineitem.show()\n",
    "    print(\"Q01 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q02(spark):\n",
    "    t1 = time.time()\n",
    "    SIZE = 15\n",
    "    TYPE = \"BRASS\"\n",
    "    REGION = \"EUROPE\"\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                s_acctbal,\n",
    "                s_name,\n",
    "                n_name,\n",
    "                p_partkey,\n",
    "                p_mfgr,\n",
    "                s_address,\n",
    "                s_phone,\n",
    "                s_comment\n",
    "            from\n",
    "                part,\n",
    "                supplier,\n",
    "                partsupp,\n",
    "                nation,\n",
    "                region\n",
    "            where\n",
    "                p_partkey = ps_partkey\n",
    "                and s_suppkey = ps_suppkey\n",
    "                and p_size = {SIZE}\n",
    "                and p_type like '%{TYPE}'\n",
    "                and s_nationkey = n_nationkey\n",
    "                and n_regionkey = r_regionkey\n",
    "                and r_name = '{REGION}'\n",
    "                and ps_supplycost = (\n",
    "                    select\n",
    "                    min(ps_supplycost)\n",
    "                    from\n",
    "                    partsupp, supplier,\n",
    "                    nation, region\n",
    "                    where\n",
    "                    p_partkey = ps_partkey\n",
    "                    and s_suppkey = ps_suppkey\n",
    "                    and s_nationkey = n_nationkey\n",
    "                    and n_regionkey = r_regionkey\n",
    "                    and r_name = '{REGION}'\n",
    "                    )\n",
    "            order by\n",
    "                s_acctbal desc,\n",
    "                n_name,\n",
    "                s_name,\n",
    "                p_partkey\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q02 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q03(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "            l_orderkey,\n",
    "            sum(l_extendedprice * (1 - l_discount)) as revenue,\n",
    "            o_orderdate,\n",
    "            o_shippriority\n",
    "        from\n",
    "            customer,\n",
    "            orders,\n",
    "            lineitem\n",
    "        where\n",
    "            c_mktsegment = 'HOUSEHOLD'\n",
    "            and c_custkey = o_custkey\n",
    "            and l_orderkey = o_orderkey\n",
    "            and o_orderdate < date '1995-03-04'\n",
    "            and l_shipdate > date '1995-03-04'\n",
    "        group by\n",
    "            l_orderkey,\n",
    "            o_orderdate,\n",
    "            o_shippriority\n",
    "        order by\n",
    "            revenue desc,\n",
    "            o_orderdate\n",
    "        limit 10\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q03 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q04(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                o_orderpriority,\n",
    "                count(*) as order_count\n",
    "            from\n",
    "                orders\n",
    "            where\n",
    "                o_orderdate >= date '1993-08-01'\n",
    "                and o_orderdate < date '1993-08-01' + interval '3' month\n",
    "                and exists (\n",
    "                    select\n",
    "                        *\n",
    "                    from\n",
    "                        lineitem\n",
    "                    where\n",
    "                        l_orderkey = o_orderkey\n",
    "                        and l_commitdate < l_receiptdate\n",
    "                )\n",
    "            group by\n",
    "                o_orderpriority\n",
    "            order by\n",
    "                o_orderpriority\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q04 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q05(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                n_name,\n",
    "                sum(l_extendedprice * (1 - l_discount)) as revenue\n",
    "            from\n",
    "                customer,\n",
    "                orders,\n",
    "                lineitem,\n",
    "                supplier,\n",
    "                nation,\n",
    "                region\n",
    "            where\n",
    "                c_custkey = o_custkey\n",
    "                and l_orderkey = o_orderkey\n",
    "                and l_suppkey = s_suppkey\n",
    "                and c_nationkey = s_nationkey\n",
    "                and s_nationkey = n_nationkey\n",
    "                and n_regionkey = r_regionkey\n",
    "                and r_name = 'ASIA'\n",
    "                and o_orderdate >= date '1996-01-01'\n",
    "                and o_orderdate < date '1996-01-01' + interval '1' year\n",
    "            group by\n",
    "                n_name\n",
    "            order by\n",
    "                revenue desc\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q05 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q06(spark):\n",
    "    t1 = time.time()\n",
    "    sql_lineitem = spark.sql(\n",
    "        \"\"\"select\n",
    "                sum(l_extendedprice * l_discount) as revenue\n",
    "            from\n",
    "                lineitem\n",
    "            where\n",
    "                l_shipdate >= date '1996-01-01'\n",
    "                and l_shipdate < date '1996-01-01' + interval '1' year\n",
    "                and l_discount between .08 and .1\n",
    "                and l_quantity < 24\"\"\"\n",
    "    )\n",
    "    sql_lineitem.show()\n",
    "    print(\"Q06 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q07(spark):\n",
    "    t1 = time.time()\n",
    "    NATION1 = \"FRANCE\"\n",
    "    NATION2 = \"GERMANY\"\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                supp_nation,\n",
    "                cust_nation,\n",
    "                l_year, sum(volume) as revenue\n",
    "            from (\n",
    "                select\n",
    "                    n1.n_name as supp_nation,\n",
    "                    n2.n_name as cust_nation,\n",
    "                    extract(year from l_shipdate) as l_year,\n",
    "                    l_extendedprice * (1 - l_discount) as volume\n",
    "                from\n",
    "                    supplier,\n",
    "                    lineitem,\n",
    "                    orders,\n",
    "                    customer,\n",
    "                    nation n1,\n",
    "                    nation n2\n",
    "                where\n",
    "                    s_suppkey = l_suppkey\n",
    "                    and o_orderkey = l_orderkey\n",
    "                    and c_custkey = o_custkey\n",
    "                    and s_nationkey = n1.n_nationkey\n",
    "                    and c_nationkey = n2.n_nationkey\n",
    "                    and (\n",
    "                    (n1.n_name = '{NATION1}' and n2.n_name = '{NATION2}')\n",
    "                    or (n1.n_name = '{NATION2}' and n2.n_name = '{NATION1}')\n",
    "                    )\n",
    "                    and l_shipdate between date '1995-01-01' and date '1996-12-31'\n",
    "                ) as shipping\n",
    "            group by\n",
    "                supp_nation,\n",
    "                cust_nation,\n",
    "                l_year\n",
    "            order by\n",
    "                supp_nation,\n",
    "                cust_nation,\n",
    "                l_year\"\"\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q07 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q08(spark):\n",
    "    t1 = time.time()\n",
    "    NATION = \"BRAZIL\"\n",
    "    REGION = \"AMERICA\"\n",
    "    TYPE = \"ECONOMY ANODIZED STEEL\"\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                o_year,\n",
    "                sum(case\n",
    "                    when nation = '{NATION}'\n",
    "                    then volume\n",
    "                    else 0\n",
    "                end) / sum(volume) as mkt_share\n",
    "            from (\n",
    "                select\n",
    "                    extract(year from o_orderdate) as o_year,\n",
    "                    l_extendedprice * (1-l_discount) as volume,\n",
    "                    n2.n_name as nation\n",
    "                from\n",
    "                    part,\n",
    "                    supplier,\n",
    "                    lineitem,\n",
    "                    orders,\n",
    "                    customer,\n",
    "                    nation n1,\n",
    "                    nation n2,\n",
    "                    region\n",
    "                where\n",
    "                    p_partkey = l_partkey\n",
    "                    and s_suppkey = l_suppkey\n",
    "                    and l_orderkey = o_orderkey\n",
    "                    and o_custkey = c_custkey\n",
    "                    and c_nationkey = n1.n_nationkey\n",
    "                    and n1.n_regionkey = r_regionkey\n",
    "                    and r_name = '{REGION}'\n",
    "                    and s_nationkey = n2.n_nationkey\n",
    "                    and o_orderdate between date '1995-01-01' and date '1996-12-31'\n",
    "                    and p_type = '{TYPE}'\n",
    "                ) as all_nations\n",
    "            group by\n",
    "                o_year\n",
    "            order by\n",
    "                o_year\"\"\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q08 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q09(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                nation,\n",
    "                o_year,\n",
    "                sum(amount) as sum_profit\n",
    "            from\n",
    "                (\n",
    "                    select\n",
    "                        n_name as nation,\n",
    "                        year(o_orderdate) as o_year,\n",
    "                        l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity as amount\n",
    "                    from\n",
    "                        part,\n",
    "                        supplier,\n",
    "                        lineitem,\n",
    "                        partsupp,\n",
    "                        orders,\n",
    "                        nation\n",
    "                    where\n",
    "                        s_suppkey = l_suppkey\n",
    "                        and ps_suppkey = l_suppkey\n",
    "                        and ps_partkey = l_partkey\n",
    "                        and p_partkey = l_partkey\n",
    "                        and o_orderkey = l_orderkey\n",
    "                        and s_nationkey = n_nationkey\n",
    "                        and p_name like '%ghost%'\n",
    "                ) as profit\n",
    "            group by\n",
    "                nation,\n",
    "                o_year\n",
    "            order by\n",
    "                nation,\n",
    "                o_year desc\"\"\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q09 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q10(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                c_custkey,\n",
    "                c_name,\n",
    "                sum(l_extendedprice * (1 - l_discount)) as revenue,\n",
    "                c_acctbal,\n",
    "                n_name,\n",
    "                c_address,\n",
    "                c_phone,\n",
    "                c_comment\n",
    "            from\n",
    "                customer,\n",
    "                orders,\n",
    "                lineitem,\n",
    "                nation\n",
    "            where\n",
    "                c_custkey = o_custkey\n",
    "                and l_orderkey = o_orderkey\n",
    "                and o_orderdate >= date '1994-11-01'\n",
    "                and o_orderdate < date '1994-11-01' + interval '3' month\n",
    "                and l_returnflag = 'R'\n",
    "                and c_nationkey = n_nationkey\n",
    "            group by\n",
    "                c_custkey,\n",
    "                c_name,\n",
    "                c_acctbal,\n",
    "                c_phone,\n",
    "                n_name,\n",
    "                c_address,\n",
    "                c_comment\n",
    "            order by\n",
    "                revenue desc\n",
    "            limit 20\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q10 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q11(spark):\n",
    "    t1 = time.time()\n",
    "    NATION = \"GERMANY\"\n",
    "    FRACTION = 0.0001\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                ps_partkey,\n",
    "                sum(ps_supplycost * ps_availqty) as value\n",
    "            from\n",
    "                partsupp,\n",
    "                supplier,\n",
    "                nation\n",
    "            where\n",
    "                ps_suppkey = s_suppkey\n",
    "                and s_nationkey = n_nationkey\n",
    "                and n_name = '{NATION}'\n",
    "            group by\n",
    "                ps_partkey having\n",
    "                        sum(ps_supplycost * ps_availqty) > (\n",
    "                    select\n",
    "                        sum(ps_supplycost * ps_availqty) * {FRACTION}\n",
    "                    from\n",
    "                        partsupp,\n",
    "                        supplier,\n",
    "                        nation\n",
    "                    where\n",
    "                        ps_suppkey = s_suppkey\n",
    "                        and s_nationkey = n_nationkey\n",
    "                        and n_name = '{NATION}'\n",
    "                    )\n",
    "                order by\n",
    "                    value desc\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q11 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q12(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                l_shipmode,\n",
    "                sum(case\n",
    "                    when o_orderpriority = '1-URGENT'\n",
    "                        or o_orderpriority = '2-HIGH'\n",
    "                        then 1\n",
    "                    else 0\n",
    "                end) as high_line_count,\n",
    "                sum(case\n",
    "                    when o_orderpriority <> '1-URGENT'\n",
    "                        and o_orderpriority <> '2-HIGH'\n",
    "                        then 1\n",
    "                    else 0\n",
    "                end) as low_line_count\n",
    "            from\n",
    "                orders,\n",
    "                lineitem\n",
    "            where\n",
    "                o_orderkey = l_orderkey\n",
    "                and l_shipmode in ('MAIL', 'SHIP')\n",
    "                and l_commitdate < l_receiptdate\n",
    "                and l_shipdate < l_commitdate\n",
    "                and l_receiptdate >= date '1994-01-01'\n",
    "                and l_receiptdate < date '1994-01-01' + interval '1' year\n",
    "            group by\n",
    "                l_shipmode\n",
    "            order by\n",
    "                l_shipmode\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q12 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q13(spark):\n",
    "    t1 = time.time()\n",
    "    WORD1 = \"special\"\n",
    "    WORD2 = \"requests\"\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                c_count, count(*) as custdist\n",
    "            from (\n",
    "                select\n",
    "                    c_custkey,\n",
    "                    count(o_orderkey)\n",
    "                from\n",
    "                    customer left outer join orders on\n",
    "                    c_custkey = o_custkey\n",
    "                    and o_comment not like '%{WORD1}%{WORD2}%'\n",
    "                group by\n",
    "                    c_custkey\n",
    "                )as c_orders (c_custkey, c_count)\n",
    "            group by\n",
    "                c_count\n",
    "            order by\n",
    "                custdist desc,\n",
    "                c_count desc\"\"\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q13 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "\n",
    "def q14(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                100.00 * sum(case\n",
    "                    when p_type like 'PROMO%'\n",
    "                        then l_extendedprice * (1 - l_discount)\n",
    "                    else 0\n",
    "                end) / sum(l_extendedprice * (1 - l_discount)) as promo_revenue\n",
    "            from\n",
    "                lineitem,\n",
    "                part\n",
    "            where\n",
    "                l_partkey = p_partkey\n",
    "                and l_shipdate >= date '1994-03-01'\n",
    "                and l_shipdate < date '1994-03-01' + interval '1' month\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q14 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q15(spark):\n",
    "    # Why `CAST` is used here?\n",
    "    # From spec the l_extendedprice and l_discount are defined as decimals. \n",
    "    # It defines decimal as having 12 digits and 2 digits after the point.\n",
    "    # See p14 in \n",
    "    # http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.1.pdf\n",
    "    t1 = time.time()\n",
    "    spark.sql(\n",
    "        \"\"\"create temp view revenue (supplier_no, total_revenue) as\n",
    "                select\n",
    "                    l_suppkey,\n",
    "                    CAST(sum(l_extendedprice * (1 - l_discount)) as DECIMAL(12,2))\n",
    "                from\n",
    "                    lineitem\n",
    "                where\n",
    "                    l_shipdate >= date '1996-01-01'\n",
    "                    and l_shipdate < date '1996-01-01' + interval '3' month\n",
    "                group by\n",
    "                    l_suppkey\"\"\"\n",
    "    )\n",
    "    total = spark.sql(\n",
    "        \"\"\"\n",
    "            select\n",
    "                s_suppkey,\n",
    "                s_name,\n",
    "                s_address,\n",
    "                s_phone,\n",
    "                total_revenue\n",
    "            from\n",
    "                supplier,\n",
    "                revenue\n",
    "            where\n",
    "                s_suppkey = supplier_no\n",
    "                and total_revenue = (\n",
    "                    select\n",
    "                        max(total_revenue)\n",
    "                    from\n",
    "                        revenue\n",
    "                )\n",
    "            order by\n",
    "                s_suppkey\"\"\"\n",
    "    )\n",
    "    spark.sql(\n",
    "        \"drop view revenue\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q15 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q16(spark):\n",
    "    t1 = time.time()\n",
    "    BRAND = \"Brand#45\"\n",
    "    TYPE = \"MEDIUM POLISHED\"\n",
    "    SIZE1 = 49\n",
    "    SIZE2 = 14\n",
    "    SIZE3 = 23\n",
    "    SIZE4 = 45\n",
    "    SIZE5 = 19\n",
    "    SIZE6 = 3\n",
    "    SIZE7 = 36\n",
    "    SIZE8 = 9\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                p_brand,\n",
    "                p_type,\n",
    "                p_size,\n",
    "                count(distinct ps_suppkey) as supplier_cnt\n",
    "            from\n",
    "                partsupp,\n",
    "                part\n",
    "            where\n",
    "                p_partkey = ps_partkey\n",
    "                and p_brand <> '{BRAND}'\n",
    "                and p_type not like '{TYPE}%'\n",
    "                and p_size in ({SIZE1}, {SIZE2}, {SIZE3}, {SIZE4}, {SIZE5}, {SIZE6}, {SIZE7}, {SIZE8})\n",
    "                and ps_suppkey not in (\n",
    "                    select\n",
    "                        s_suppkey\n",
    "                    from\n",
    "                        supplier\n",
    "                    where\n",
    "                        s_comment like '%Customer%Complaints%'\n",
    "                )\n",
    "            group by\n",
    "                p_brand,\n",
    "                p_type,\n",
    "                p_size\n",
    "            order by\n",
    "                supplier_cnt desc,\n",
    "                p_brand,\n",
    "                p_type,\n",
    "                p_size\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q16 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q17(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                sum(l_extendedprice) / 7.0 as avg_yearly\n",
    "            from\n",
    "                lineitem,\n",
    "                part\n",
    "            where\n",
    "                p_partkey = l_partkey\n",
    "                and p_brand = 'Brand#23'\n",
    "                and p_container = 'MED BOX'\n",
    "                and l_quantity < (\n",
    "                    select\n",
    "                        0.2 * avg(l_quantity)\n",
    "                    from\n",
    "                        lineitem\n",
    "                    where\n",
    "                        l_partkey = p_partkey\n",
    "                )\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q17 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q18(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                c_name,\n",
    "                c_custkey,\n",
    "                o_orderkey,\n",
    "                o_orderdate,\n",
    "                o_totalprice,\n",
    "                sum(l_quantity)\n",
    "            from\n",
    "                customer,\n",
    "                orders,\n",
    "                lineitem\n",
    "            where\n",
    "                o_orderkey in (\n",
    "                    select\n",
    "                        l_orderkey\n",
    "                    from\n",
    "                        lineitem\n",
    "                    group by\n",
    "                        l_orderkey having\n",
    "                            sum(l_quantity) > 300\n",
    "                )\n",
    "                and c_custkey = o_custkey\n",
    "                and o_orderkey = l_orderkey\n",
    "            group by\n",
    "                c_name,\n",
    "                c_custkey,\n",
    "                o_orderkey,\n",
    "                o_orderdate,\n",
    "                o_totalprice\n",
    "            order by\n",
    "                o_totalprice desc,\n",
    "                o_orderdate\n",
    "            limit 100\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q18 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q19(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                sum(l_extendedprice* (1 - l_discount)) as revenue\n",
    "            from\n",
    "                lineitem,\n",
    "                part\n",
    "            where\n",
    "                (\n",
    "                    p_partkey = l_partkey\n",
    "                    and p_brand = 'Brand#31'\n",
    "                    and p_container in ('SM CASE', 'SM BOX', 'SM PACK', 'SM PKG')\n",
    "                    and l_quantity >= 4 and l_quantity <= 4 + 10\n",
    "                    and p_size between 1 and 5\n",
    "                    and l_shipmode in ('AIR', 'AIR REG')\n",
    "                    and l_shipinstruct = 'DELIVER IN PERSON'\n",
    "                )\n",
    "                or\n",
    "                (\n",
    "                    p_partkey = l_partkey\n",
    "                    and p_brand = 'Brand#43'\n",
    "                    and p_container in ('MED BAG', 'MED BOX', 'MED PKG', 'MED PACK')\n",
    "                    and l_quantity >= 15 and l_quantity <= 25\n",
    "                    and p_size between 1 and 10\n",
    "                    and l_shipmode in ('AIR', 'AIR REG')\n",
    "                    and l_shipinstruct = 'DELIVER IN PERSON'\n",
    "                )\n",
    "                or\n",
    "                (\n",
    "                    p_partkey = l_partkey\n",
    "                    and p_brand = 'Brand#43'\n",
    "                    and p_container in ('LG CASE', 'LG BOX', 'LG PACK', 'LG PKG')\n",
    "                    and l_quantity >= 26 and l_quantity <= 36\n",
    "                    and p_size between 1 and 15\n",
    "                    and l_shipmode in ('AIR', 'AIR REG')\n",
    "                    and l_shipinstruct = 'DELIVER IN PERSON'\n",
    "                )\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q19 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q20(spark):\n",
    "    t1 = time.time()\n",
    "    total = spark.sql(\n",
    "        \"\"\"select\n",
    "                s_name,\n",
    "                s_address\n",
    "            from\n",
    "                supplier,\n",
    "                nation\n",
    "            where\n",
    "                s_suppkey in (\n",
    "                    select\n",
    "                        ps_suppkey\n",
    "                    from\n",
    "                        partsupp\n",
    "                    where\n",
    "                        ps_partkey in (\n",
    "                            select\n",
    "                                p_partkey\n",
    "                            from\n",
    "                                part\n",
    "                            where\n",
    "                                p_name like 'azure%'\n",
    "                        )\n",
    "                        and ps_availqty > (\n",
    "                            select\n",
    "                                0.5 * sum(l_quantity)\n",
    "                            from\n",
    "                                lineitem\n",
    "                            where\n",
    "                                l_partkey = ps_partkey\n",
    "                                and l_suppkey = ps_suppkey\n",
    "                                and l_shipdate >= date '1996-01-01'\n",
    "                                and l_shipdate < date '1996-01-01' + interval '1' year\n",
    "                        )\n",
    "                )\n",
    "                and s_nationkey = n_nationkey\n",
    "                and n_name = 'JORDAN'\n",
    "            order by\n",
    "                s_name\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q20 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "def q21(spark):\n",
    "    t1 = time.time()\n",
    "    NATION = \"SAUDI ARABIA\"\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                s_name,\n",
    "                count(*) as numwait\n",
    "            from\n",
    "                supplier,\n",
    "                lineitem l1,\n",
    "                orders,\n",
    "                nation\n",
    "            where\n",
    "                s_suppkey = l1.l_suppkey\n",
    "                and o_orderkey = l1.l_orderkey\n",
    "                and o_orderstatus = 'F'\n",
    "                and l1.l_receiptdate > l1.l_commitdate\n",
    "                and exists (\n",
    "                    select\n",
    "                        *\n",
    "                    from\n",
    "                        lineitem l2\n",
    "                    where\n",
    "                        l2.l_orderkey = l1.l_orderkey\n",
    "                        and l2.l_suppkey <> l1.l_suppkey\n",
    "                )\n",
    "                and not exists (\n",
    "                    select\n",
    "                        *\n",
    "                    from\n",
    "                        lineitem l3\n",
    "                    where\n",
    "                        l3.l_orderkey = l1.l_orderkey\n",
    "                        and l3.l_suppkey <> l1.l_suppkey\n",
    "                        and l3.l_receiptdate > l3.l_commitdate\n",
    "                )\n",
    "                and s_nationkey = n_nationkey\n",
    "                and n_name = '{NATION}'\n",
    "            group by\n",
    "                s_name\n",
    "            order by\n",
    "                numwait desc,\n",
    "                s_name\"\"\"\n",
    "    )\n",
    "    total.show()\n",
    "    print(\"Q21 Execution time (s): \", time.time() - t1)\n",
    "\n",
    "\n",
    "\n",
    "def q22(spark):\n",
    "    t1 = time.time()\n",
    "    I1 = 13\n",
    "    I2 = 31\n",
    "    I3 = 23\n",
    "    I4 = 29\n",
    "    I5 = 30\n",
    "    I6 = 18\n",
    "    I7 = 17\n",
    "    total = spark.sql(\n",
    "        f\"\"\"select\n",
    "                cntrycode,\n",
    "                count(*) as numcust,\n",
    "                sum(c_acctbal) as totacctbal\n",
    "            from (\n",
    "                select\n",
    "                    substring(c_phone from 1 for 2) as cntrycode,\n",
    "                    c_acctbal\n",
    "                from\n",
    "                    customer\n",
    "                where\n",
    "                    substring(c_phone from 1 for 2) in\n",
    "                        ('{I1}','{I2}','{I3}','{I4}','{I5}','{I6}','{I7}')\n",
    "                    and c_acctbal > (\n",
    "                        select\n",
    "                            avg(c_acctbal)\n",
    "                        from\n",
    "                            customer\n",
    "                        where\n",
    "                            c_acctbal > 0.00\n",
    "                            and substring (c_phone from 1 for 2) in\n",
    "                                ('{I1}','{I2}','{I3}','{I4}','{I5}','{I6}','{I7}')\n",
    "                    )\n",
    "                    and not exists (\n",
    "                        select\n",
    "                            *\n",
    "                        from\n",
    "                            orders\n",
    "                        where\n",
    "                            o_custkey = c_custkey\n",
    "                    )\n",
    "                ) as custsale\n",
    "            group by\n",
    "                cntrycode\n",
    "            order by\n",
    "                cntrycode\"\"\"\n",
    "    )\n",
    "\n",
    "    total.show()\n",
    "    print(\"Q22 Execution time (s): \", time.time() - t1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark TPC-H Queries\n",
    "\n",
    "Replace `folder` value with path to your generated dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def run_queries(data_folder, spark):\n",
    "\n",
    "    # Load the data\n",
    "    t1 = time.time()\n",
    "    load_lineitem(data_folder, spark)\n",
    "    load_orders(data_folder, spark)\n",
    "    load_customer(data_folder, spark)\n",
    "    load_nation(data_folder, spark)\n",
    "    load_region(data_folder, spark)\n",
    "    load_supplier(data_folder, spark)\n",
    "    load_part(data_folder, spark)\n",
    "    load_partsupp(data_folder, spark)\n",
    "    print(\"Reading time (s): \", time.time() - t1)\n",
    "\n",
    "    # Run the Queries:\n",
    "    t1 = time.time()   \n",
    "    q01(spark)\n",
    "    q02(spark)\n",
    "    q03(spark)\n",
    "    q04(spark)\n",
    "    q05(spark)\n",
    "    q06(spark)\n",
    "    q07(spark)\n",
    "    q08(spark)\n",
    "    q09(spark)\n",
    "    q10(spark)\n",
    "    q11(spark)\n",
    "    q12(spark)\n",
    "    q13(spark)\n",
    "    q14(spark)\n",
    "    q15(spark)\n",
    "    q16(spark)\n",
    "    q17(spark)\n",
    "    q18(spark)\n",
    "    q19(spark)\n",
    "    q20(spark)\n",
    "    q21(spark)\n",
    "    q22(spark)\n",
    "    print(\"Total Query time (s): \", time.time() - t1)\n",
    "\n",
    "def main():\n",
    "    # Replace with data folder path\n",
    "    folder = \"path/to/data\"\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(\"TPC-H Queries with PySpark\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    run_queries(folder, spark)\n",
    "\n",
    "main()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV2",
   "language": "python",
   "name": "dev2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}