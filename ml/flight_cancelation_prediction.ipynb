{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sophisticated-philadelphia",
   "metadata": {},
   "source": [
    "# Predicting Flight Delays\n",
    "\n",
    "This example shows use of classification models to predict flight delays. \n",
    "Original example can be found [here](https://github.com/frenchlam/dask_CDSW/blob/master/03_Dask_ML-LargeDS.ipynb) (dataset is [here](https://github.com/frenchlam/dask_CDSW/blob/master/data/1988.csv.bz2))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe9aad-4d47-4b4a-9cf9-111f63d31ff4",
   "metadata": {},
   "source": [
    "### Start an IPyParallel cluster \n",
    "Run the following code in a cell to start an IPyParallel cluster. 8 cores are used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d9618b-8249-405f-8fd9-06f942194cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.13engine/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.environ.get(\"BODO_PLATFORM_WORKSPACE_UUID\",'NA') == 'NA':\n",
    "    import ipyparallel as ipp\n",
    "    import psutil; n = min(psutil.cpu_count(logical=False), 8)\n",
    "    rc = ipp.Cluster(engines='mpi', n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d26f5-220b-46e6-bd13-34fa767ef327",
   "metadata": {},
   "source": [
    "### Verifying your setup\n",
    "Run the following code to verify that your IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610e813c-8c01-473d-87f6-717dcb1aee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello World from rank 3. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Hello World from rank 6. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Hello World from rank 5. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello World from rank 0. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Hello World from rank 7. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Hello World from rank 4. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello World from rank 1. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello World from rank 2. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import bodo\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-norway",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - Scikit-learn to build and evaluate regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrative-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-mortgage",
   "metadata": {},
   "source": [
    "## Part 1. Pre-processing in Pandas\n",
    "\n",
    "### 1. Read flights dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relative-advertising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [01:18<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0]    Month  DayofMonth  DayOfWeek  CRSDepTime  CRSArrTime UniqueCarrier  \\\n",
       "0      1           9          6        1331        1435            PI   \n",
       "1      1          10          7        1331        1435            PI   \n",
       "2      1          11          1        1331        1435            PI   \n",
       "3      1          12          2        1331        1435            PI   \n",
       "4      1          13          3        1331        1435            PI   \n",
       "\n",
       "   FlightNum Origin Dest  Cancelled  \n",
       "0        942    SYR  BWI          0  \n",
       "1        942    SYR  BWI          0  \n",
       "2        942    SYR  BWI          0  \n",
       "3        942    SYR  BWI          0  \n",
       "4        942    SYR  BWI          0  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [01:19<00:00,  9.90s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(cache=True)\n",
    "def read_flights(input_file):\n",
    "    flight_df = pd.read_csv(input_file, sep=',', header=0,\n",
    "        usecols=['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'Origin', 'Dest','Cancelled'])    \n",
    "    print(flight_df.head())    \n",
    "    return flight_df\n",
    "\n",
    "input_file = \"s3://bodo-example-data/flights/1988.csv.bz2\"\n",
    "flight_df = read_flights(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-anatomy",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering\n",
    "1. Create routes from origin and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stainless-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:15<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] LAX_SFO    20750\n",
       "SFO_LAX    20658\n",
       "LAX_PHX    13461\n",
       "PHX_LAX    13273\n",
       "LAX_LAS    12175\n",
       "LGA_BOS    12027\n",
       "LAS_LAX    11801\n",
       "SJC_LAX    11535\n",
       "LAX_SJC    11292\n",
       "BOS_LGA    11141\n",
       "Name: route, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:15<00:00,  1.90s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(cache=True)\n",
    "def create_routes(flight_df):\n",
    "    flight_df['route'] = flight_df['Origin'] + \"_\" + flight_df['Dest']\n",
    "    # show top 20 routes - As defined by nb of flights\n",
    "    top_routes = flight_df['route'].value_counts(ascending=False)\n",
    "    print(top_routes.head(10))\n",
    "    #focus on 50 biggest routes - As defined by nb of flights \n",
    "    route_lst=top_routes.head(50)\n",
    "    flight_df = flight_df[flight_df['route'].isin(route_lst.index)]\n",
    "    return flight_df\n",
    "\n",
    "flight_df = create_routes(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-draft",
   "metadata": {},
   "source": [
    "2. Look at their cancellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thousand-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:03<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0]       route  count  nb_cancelled\n",
       "0   LAX_SFO  20750           228\n",
       "32  SFO_LAX  20658           206\n",
       "43  LAX_PHX  13461            78\n",
       "29  PHX_LAX  13273            71\n",
       "35  LAX_LAS  12175            58\n",
       "41  LGA_BOS  12027           287\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1]       route  count  nb_cancelled\n",
       "19  LAS_LAX  11801            47\n",
       "10  SJC_LAX  11535            71\n",
       "42  LAX_SJC  11292            71\n",
       "24  BOS_LGA  11141           243\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:03<00:00,  2.38tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(cache=True)\n",
    "def check_cancelations(flight_df):\n",
    "    res = flight_df[['route', 'Cancelled', 'Month']].groupby(by='route')\\\n",
    "         .agg({'Month':'size', 'Cancelled':'sum'})\\\n",
    "        .rename(columns={'Month':'count','Cancelled':'nb_cancelled'}) \\\n",
    "        .reset_index()\\\n",
    "        .sort_values(['count'], ascending=False)\n",
    "    print(res.head(10))\n",
    "\n",
    "check_cancelations(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wrong-scoop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] (487253, 11)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit\n",
    "def print_info(flight_df):\n",
    "    print(flight_df.shape)\n",
    "print_info(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-verse",
   "metadata": {},
   "source": [
    "3. Quick sanity check - count number of null values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charming-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:10<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Month            0\n",
       "DayofMonth       0\n",
       "DayOfWeek        0\n",
       "CRSDepTime       0\n",
       "CRSArrTime       0\n",
       "UniqueCarrier    0\n",
       "FlightNum        0\n",
       "Origin           0\n",
       "Dest             0\n",
       "Cancelled        0\n",
       "route            0\n",
       "dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:10<00:00,  1.36s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit\n",
    "def check_count(flight_df):\n",
    "    \n",
    "    print(flight_df.isnull().sum())\n",
    "    \n",
    "check_count(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-anderson",
   "metadata": {},
   "source": [
    "### 3. Feature and label encoding encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-demographic",
   "metadata": {},
   "source": [
    "#### 1. Encode Labels using Cancelled column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designed-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:08<00:00,  1.05s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(cache=True)\n",
    "def encode_labels(flight_df):\n",
    "    flight_df.Cancelled = pd.Categorical(flight_df.Cancelled)\n",
    "    flight_df['Label'] = flight_df.Cancelled.cat.codes\n",
    "    flight_df.drop(['Cancelled'], axis=1, inplace=True)\n",
    "    return flight_df\n",
    "\n",
    "flight_df = encode_labels(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-basics",
   "metadata": {},
   "source": [
    "#### 2. Feature Encoding\n",
    "\n",
    "This is needed because sklearn only supports numerical values\n",
    "\n",
    "a. Get airport unique values\n",
    "\n",
    "b. Encode origin, destination, and route features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "postal-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:05<00:00,  1.56tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def get_airport_list(flight_df):\n",
    "    airport_list = np.sort((pd.concat((flight_df['Origin'], flight_df['Dest']))).unique())\n",
    "    return airport_list\n",
    "\n",
    "airport_list = get_airport_list(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extra-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:14<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Encoding time:  0.12577081399922463  sec\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:14<00:00,  1.82s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "@bodo.jit(cache=True)\n",
    "def encode_features(flight_df, airport_list):\n",
    "    t1 = time.time()    \n",
    "    # encode airlines \n",
    "    le_carrier = LabelEncoder()\n",
    "    flight_df['Carrier_encoded'] = pd.Series(le_carrier.fit_transform(flight_df['UniqueCarrier'].values))\n",
    "    # Encode airports : Using same encoder for both origin and dest ( consistent encoding of airports )\n",
    "    le_airport = LabelEncoder()\n",
    "    le_airport.fit(airport_list)\n",
    "    flight_df['Origin_encoded'] = pd.Series(le_airport.transform(flight_df['Origin']))\n",
    "    flight_df['Dest_encoded'] = pd.Series(le_airport.transform(flight_df['Dest']))\n",
    "    # Encode routes \n",
    "    le_route = LabelEncoder()\n",
    "    flight_df['route_encoded'] = pd.Series(le_route.fit_transform(flight_df['route'].values))\n",
    "    print(\"Encoding time: \", (time.time()-t1), \" sec\")\n",
    "    return flight_df\n",
    "\n",
    "flight_df = encode_features(flight_df, airport_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stupid-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:08<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0]         UniqueCarrier  Carrier_encoded Origin  Origin_encoded Dest  \\\n",
       "504561             UA               11    SFO              22  LAX   \n",
       "89184              WN               13    HOU               8  DAL   \n",
       "896267             UA               11    ORD              16  DTW   \n",
       "703945             DL                3    SAN              19  LAX   \n",
       "2510421            AA                0    DEN               4  DFW   \n",
       "2396774            CO                2    DFW               5  IAH   \n",
       "2211575            UA               11    ORD              16  DEN   \n",
       "2198174            UA               11    LGA              12  ORD   \n",
       "3182400            HP                5    LAX              11  PHX   \n",
       "4801132            UA               11    SFO              22  SEA   \n",
       "\n",
       "         Dest_encoded    route  route_encoded  \n",
       "504561             11  SFO_LAX             45  \n",
       "89184               2  HOU_DAL             12  \n",
       "896267              6  ORD_DTW             29  \n",
       "703945             11  SAN_LAX             38  \n",
       "2510421             5  DEN_DFW              7  \n",
       "2396774             9  DFW_IAH              9  \n",
       "2211575             4  ORD_DEN             28  \n",
       "2198174            16  LGA_ORD             24  \n",
       "3182400            18  LAX_PHX             17  \n",
       "4801132            21  SFO_SEA             47  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:08<00:00,  1.08s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(cache=True)\n",
    "def sample(flight_df):\n",
    "    print(flight_df[['UniqueCarrier','Carrier_encoded','Origin','Origin_encoded',\n",
    "           'Dest', 'Dest_encoded', 'route', 'route_encoded' ]].sample(10))\n",
    "    \n",
    "sample(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "saved-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:20<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Data splitting time:  0.18990181499975733  sec\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:20<00:00,  2.55s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from sklearn.model_selection import train_test_split\n",
    "@bodo.jit(cache=True)\n",
    "def split_data(flight_df):\n",
    "    t1 = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flight_df.drop(['UniqueCarrier','Origin','Dest','route'],axis=1),\n",
    "                                                    flight_df['Label'], \n",
    "                                                    test_size=0.3, train_size=0.7,\n",
    "                                                    random_state=100)\n",
    "    print(\"Data splitting time: \", (time.time()-t1), \" sec\")    \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-berkeley",
   "metadata": {},
   "source": [
    "## Part 2: Model Training - Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-cleaner",
   "metadata": {},
   "source": [
    "### 1. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifth-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:15<?, ?tasks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:15<00:00,  1.91s/tasks]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] RandomForestClassifier fit and predict time:  6.684258414000396\n",
       "Accuracy score 1.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score # evaluation metric\n",
    "@bodo.jit(cache=True)\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train.to_numpy(), y_train.values)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(\"RandomForestClassifier fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "rf_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-museum",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ready-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:03<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stderr:0] /var/folders/3j/b79y0nbj7jj466srs2dc025r0000gn/T/ipykernel_49022/3554810041.py:12: BodoWarning: Data is distributed so Bodo will fit model with SGD solver optimization (SGDClassifier)\n",
       "  lr_model(X_train, X_test, y_train, y_test)\n",
       "/Users/runner/opt/anaconda3/envs/T7/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/8 [00:03<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Logistic Regression fit and predict time:  0.451817635000225\n",
       "Accuracy score 0.9815770030647986\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 8/8 [00:03<00:00,  2.03tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score  # evaluation metric\n",
    "@bodo.jit(cache=True)\n",
    "def lr_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train.values)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(\"Logistic Regression fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "lr_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping controller\n",
      "Controller stopped: {'exit_code': 0, 'pid': 49007, 'identifier': 'ipcontroller-1652912636-2mh3-48843'}\n",
      "Stopping engine(s): 1652912637\n",
      "engine set stopped 1652912637: {'exit_code': 0, 'pid': 49019, 'identifier': 'ipengine-1652912636-2mh3-1652912637-48843'}\n"
     ]
    }
   ],
   "source": [
    "# To stop the cluster run the following command. \n",
    "rc.cluster.stop_cluster_sync()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16c8ad1c156570dbb9b8c59e261dba05f4270231d6ef51b3fb205099379bfe9f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
