{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acoustic-camping",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection With Machine Learning in Python\n",
    "\n",
    "This example shows use of classification to help credit card company to detect potential fraud cases. \n",
    "Original example can be found [here](https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-mongolia",
   "metadata": {},
   "source": [
    "### Notes on running this example:\n",
    "\n",
    "By defaults runs use Bodo. Hence, data is distributed in chunks across processes.\n",
    "\n",
    "The current results are based on running on one **m5.12xlarge** instance (24 cores, 192GiB memory)\n",
    "\n",
    "The dataset can be downloaded from Kaggle [here](https://www.kaggle.com/mlg-ulb/creditcardfraud) or use S3 Bucket (`s3://bodo-examples-data/creditcard/creditcard.csv`)\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you add your AWS account credentials to access the data (if using S3 bucket link). \n",
    "2. If you want to run the example using pandas only (without Bodo):\n",
    "    1. Comment lines magic expression (`%%px`) and bodo decorator (`@bodo.jit`) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning.\n",
    "3. For xgboost package, build it from source with MPI enabled (this step is already done on Bodo Platform)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-enzyme",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - Numpy to work with arrays\n",
    " - scikit-learn to build and evaluate classification models\n",
    " - xgboost for xgboost classifier model algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arabic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bodo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler # data normalization\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm\n",
    "from xgboost import XGBClassifier # XGBoost algorithm\n",
    "from sklearn.svm import LinearSVC # SVM classification algorithm\n",
    "from sklearn.metrics import accuracy_score # evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlled-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"your_access_key_id\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"your_secret_access_key\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-daughter",
   "metadata": {},
   "source": [
    "## Data Processing and EDA\n",
    "1. Load dataset\n",
    "2. Compute the percentage of fraud cases in the overall recorded transcations.\n",
    "3. Get a statistical view of both fraud and non-fraud transaction amount data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weighted-being",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Read Time:  0.9684278964996338\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def load_data():\n",
    "    start = time.time()\n",
    "    df = pd.read_csv('s3://bodo-examples-data/creditcard/creditcard.csv')\n",
    "    df.drop('Time', axis = 1, inplace = True)\n",
    "    end = time.time()\n",
    "    print(\"Read Time: \", (end-start))\n",
    "    return df\n",
    "\n",
    "df = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tender-indiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "--------------------------------------------\n",
      "Total number of cases are  284807\n",
      "Number of Non-fraud cases are  284315\n",
      "Number of fraud cases are 492\n",
      "Percentage of fraud cases is  0.17\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "NON-FRAUD CASE AMOUNT STATS\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "FRAUD CASE AMOUNT STATS\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'])\n",
    "def data_processing(df):\n",
    "    cases = len(df)\n",
    "    nonfraud_count = len(df[df.Class == 0])\n",
    "    fraud_count = len(df[df.Class == 1])\n",
    "    fraud_percentage = round(fraud_count/nonfraud_count*100, 2)\n",
    "    print('--------------------------------------------')\n",
    "    print('Total number of cases are ', cases)\n",
    "    print('Number of Non-fraud cases are ', nonfraud_count)\n",
    "    print('Number of fraud cases are', fraud_count)\n",
    "    print('Percentage of fraud cases is ', fraud_percentage)\n",
    "    print('--------------------------------------------')    \n",
    "    nonfraud_cases = df[df.Class == 0]\n",
    "    fraud_cases = df[df.Class == 1]\n",
    "    print('--------------------------------------------')\n",
    "    print('NON-FRAUD CASE AMOUNT STATS')\n",
    "    print(nonfraud_cases.Amount.describe())\n",
    "    print('FRAUD CASE AMOUNT STATS')    \n",
    "    print(fraud_cases.Amount.describe())\n",
    "    print('--------------------------------------------')    \n",
    "\n",
    "data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-mathematics",
   "metadata": {},
   "source": [
    "## Feature Selection & Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-directory",
   "metadata": {},
   "source": [
    "### 1. Normalize `Amount` variable\n",
    "`Amount` variable varies when compared to the rest of the variables. To reduce its range of values, we normalize it using the `StandardScaler` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incomplete-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "StandardScaler time:  0.06013607978820801\n",
      "0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "4   -0.073403\n",
      "5   -0.338556\n",
      "6   -0.333279\n",
      "7   -0.190107\n",
      "8    0.019392\n",
      "9   -0.338516\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def sc(df):\n",
    "    start = time.time()    \n",
    "    sc = StandardScaler()\n",
    "    amount = df['Amount'].values\n",
    "    amount = amount.reshape(-1,1)\n",
    "    sc.fit(amount)\n",
    "    df['Amount'] = (sc.transform(amount)).ravel()\n",
    "    print(\"StandardScaler time: \", time.time() - start)\n",
    "    print(df['Amount'].head(10))\n",
    "    \n",
    "sc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-viking",
   "metadata": {},
   "source": [
    "### 2. Split the data into a training set and testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "genuine-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "train_test_split time:  0.001360177993774414\n",
      "X_train samples : [[-1.27923083 -0.15330333  3.29631037  3.32044136  1.13901754  0.54234305\n",
      "  -0.72992832 -0.05177411  0.92271182  0.84594969  1.38923569 -2.44018135\n",
      "   1.09921626  0.76496092 -1.32315853 -0.28971316  0.65615985  0.77523608\n",
      "   1.52883351  0.0286392  -0.40974641 -0.34257494 -0.49329682 -0.01704646\n",
      "  -0.10740384  0.10116408 -0.19794013 -0.43565366 -0.35322939]]\n",
      "X_test samples : [[-1.46317756  1.53882499  0.78746456 -0.10219179 -0.62638956 -0.35972277\n",
      "  -0.21373356  1.08709589 -0.76867278 -0.32041171  1.37707623  0.95539556\n",
      "  -0.29877328  1.00682748  0.36061527  0.28524413  0.05467376 -0.27212213\n",
      "  -0.17142973 -0.02906554 -0.08161953 -0.40711758  0.13531346  0.19218949\n",
      "  -0.23768612  0.08036209  0.13556789  0.03238003 -0.31328851]]\n",
      "y_train samples : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test samples : [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def data_split(df):\n",
    "    X = df.drop('Class', axis = 1).values\n",
    "    y = df['Class'].values.astype(np.int64)\n",
    "    start = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "    print(\"train_test_split time: \", time.time() - start)    \n",
    "    print('X_train samples :', X_train[:1])\n",
    "    print('X_test samples :', X_test[0:1])\n",
    "    print('y_train samples :', y_train[0:20])\n",
    "    print('y_test samples :', y_test[0:20])    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = data_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-antarctica",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Here we have built four different types of classification models and evaluate these models using accuracy score metrics provided by scikit-learn package.\n",
    "\n",
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hidden-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "WARNING: Data is distributed so Bodo will fit model with SGD solver optimization (SGDClassifier)\n",
      "LogisticRegression fit and predict time:  0.07842183113098145\n",
      "Accuracy score of the Logistic Regression model is 0.9993330525133389\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def lr_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_yhat = lr.predict(X_test)\n",
    "    print(\"LogisticRegression fit and predict time: \", time.time()-start)\n",
    "    print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "    \n",
    "    \n",
    "lr_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-lawrence",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intensive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "RandomForestClassifier fit and predict time:  4.058526992797852\n",
      "Accuracy score of the Random Forest Tree model is 0.9994208087615838\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier(max_depth = 4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_yhat = rf.predict(X_test)\n",
    "    print(\"RandomForestClassifier fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "\n",
    "rf_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-stamp",
   "metadata": {},
   "source": [
    "#### 3. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extraordinary-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "XGBClassifier fit and predict time:  1.8004610538482666\n",
      "Accuracy score of the XGBoost model is 0.9980342600393148\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def xgb_model(X_train, X_test, y_train, y_test):  \n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(max_depth = 4)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_yhat = xgb.predict(X_test)\n",
    "    print(\"XGBClassifier fit and predict time: \", time.time()-start) \n",
    "    print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
    "\n",
    "xgb_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-jones",
   "metadata": {},
   "source": [
    "#### 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "WARNING: Data is distributed so Bodo will fit model with SGD solver optimization (SGDClassifier)\n",
      "LinearSVC fit and predict time:  0.13797593116760254\n",
      "Accuracy score of the Linear Support Vector Classification model is 0.9993330525133389\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def lsvc_model(X_train, X_test, y_train, y_test):  \n",
    "    start = time.time()\n",
    "    lsvc = LinearSVC(random_state=42)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    lsvc_yhat = lsvc.predict(X_test)\n",
    "    print(\"LinearSVC fit and predict time: \", time.time()-start) \n",
    "    print('Accuracy score of the Linear Support Vector Classification model is {}'.format(accuracy_score(y_test, lsvc_yhat)))\n",
    "\n",
    "lsvc_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-house",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
