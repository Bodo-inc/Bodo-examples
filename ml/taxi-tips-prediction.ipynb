{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-ghost",
   "metadata": {},
   "source": [
    "# NYC Yellow Taxi Tips Prediction With Machine Learning in Python\n",
    "\n",
    "This example shows use of regression models to predict taxi tip fractions. \n",
    "Original example can be found [here](https://github.com/saturncloud/workshop-scaling-ml/blob/main/04-large-dataset.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-intelligence",
   "metadata": {},
   "source": [
    "### Notes on running this example:\n",
    "\n",
    "By defaults runs use Bodo. Hence, data is distributed in chunks across processes.\n",
    "\n",
    "The current results are based on running on one **m5.12xlarge** instance (24 cores, 192GiB memory)\n",
    "\n",
    "The dataset can be downloaded from S3 bucket (`s3://bodo-examples-data/nyc-taxi/yellow_tripdata_2019.csv`)\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you add your AWS account credentials to access the data. \n",
    "2. If you want to run the example using pandas only (without Bodo):\n",
    "    1. Comment lines magic expression (`%%px`) and bodo decorator (`@bodo.jit`) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-asset",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - scikit-learn to build and evaluate regression models\n",
    " - xgboost for xgboost regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "japanese-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bodo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"your_aws_access_key_id\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"your_aws_secret_access_key\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-director",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weird-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Reading time:  23.072887182235718\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
      "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
      "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
      "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
      "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0            1.5           1                  N           151           239   \n",
      "1            2.6           1                  N           239           246   \n",
      "2            0.0           1                  N           236           236   \n",
      "3            0.0           1                  N           193           193   \n",
      "4            0.0           2                  N           193           193   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1          7.0    0.5      0.5        1.65           0.0   \n",
      "1             1         14.0    0.5      0.5        1.00           0.0   \n",
      "2             1          4.5    0.5      0.5        0.00           0.0   \n",
      "3             2          3.5    0.5      0.5        0.00           0.0   \n",
      "4             2         52.0    0.0      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3          9.95                   NaN  \n",
      "1                    0.3         16.30                   NaN  \n",
      "2                    0.3          5.80                   NaN  \n",
      "3                    0.3          7.55                   NaN  \n",
      "4                    0.3         55.55                   NaN  \n",
      "(84399019, 18)\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=[\"taxi\"], cache=True)\n",
    "def get_taxi_trips():\n",
    "    start = time.time()\n",
    "    taxi = pd.read_csv(\n",
    "        \"s3://bodo-examples-data/nyc-taxi/yellow_tripdata_2019.csv\",\n",
    "        parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    )\n",
    "    print(\"Reading time: \", time.time() - start)\n",
    "    print(taxi.head())\n",
    "    print(taxi.shape)\n",
    "    return taxi\n",
    "    \n",
    "taxi = get_taxi_trips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-tsunami",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-cherry",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "1. Create features before performing any data splitting.\n",
    "2. Split data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suited-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Data preparation time:  1.9029159545898438\n",
      "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
      "0             1.0                1.0          0.0              24.0   \n",
      "1             1.0                1.0          0.0              24.0   \n",
      "2             4.0               51.0         13.0             109.0   \n",
      "3             2.0               48.0         15.0              63.0   \n",
      "4             2.0               48.0         15.0              63.0   \n",
      "\n",
      "   pickup_minute  passenger_count  tip_fraction  \n",
      "0           46.0              1.0      0.235714  \n",
      "1           59.0              1.0      0.071429  \n",
      "2           48.0              3.0      0.000000  \n",
      "3           52.0              5.0      0.000000  \n",
      "4           56.0              5.0      0.000000  \n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=['taxi_df'], cache=True)\n",
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    start = time.time()    \n",
    "    df = taxi_df[taxi_df.fare_amount > 0]['tpep_pickup_datetime', 'passenger_count', 'tip_amount', 'fare_amount'].copy()  # avoid divide-by-zero\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df['pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count', 'tip_fraction'].astype(float).fillna(-1)\n",
    "    print(\"Data preparation time: \", time.time() - start)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "taxi_feat = prep_df(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bottom-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=[\"taxi_feat\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"])\n",
    "def data_split(taxi_feat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        taxi_feat['pickup_weekday', \n",
    "                    'pickup_weekofyear', \n",
    "                    'pickup_hour', \n",
    "                    'pickup_week_hour', \n",
    "                    'pickup_minute', \n",
    "                    'passenger_count'], \n",
    "        taxi_feat['tip_fraction'], \n",
    "        test_size=0.3,\n",
    "        train_size=0.7,        \n",
    "        random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(taxi_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-surprise",
   "metadata": {},
   "source": [
    "## Train Model over large dataset\n",
    "\n",
    "We'll train a linear model to predict tip_fraction and evaluate these models against the test set using RMSE.\n",
    "\n",
    "#### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rocky-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "WARNING: Data is distributed so Bodo will fit model with SGD solver optimization (SGDRegressor)\n",
      "Linear Regression fitting time:  23.97879195213318\n",
      "Linear Regression prediction time:  0.04464912414550781\n",
      "15.823265226536849\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def lr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    lr = LinearRegression()\n",
    "    lr_fitted = lr.fit(X_train, y_train)\n",
    "    print(\"Linear Regression fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    lr_preds = lr_fitted.predict(X_test)\n",
    "    print(\"Linear Regression prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, lr_preds, squared=False))\n",
    "    \n",
    "lr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-julian",
   "metadata": {},
   "source": [
    "#### 2. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collaborative-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "WARNING: Data is distributed so Bodo will fit model with SGD solver optimization (SGDRegressor)\n",
      "Ridge fitting time:  24.07288694381714\n",
      "Ridge prediction time:  0.04629015922546387\n",
      "15.82342741087518\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'])\n",
    "def rr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    rr = Ridge()\n",
    "    rr_fitted = rr.fit(X_train, y_train)\n",
    "    print(\"Ridge fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    rr_preds = rr_fitted.predict(X_test)\n",
    "    print(\"Ridge prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, rr_preds, squared=False))\n",
    "    \n",
    "rr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-session",
   "metadata": {},
   "source": [
    "#### 3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executed-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "WARNING: Data is distributed so Bodo will fit model with SGD solver optimization (SGDRegressor)\n",
      "Lasso fitting time:  23.464781045913696\n",
      "Lasso prediction time:  0.04559612274169922\n",
      "15.822413849001796\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'])\n",
    "def lsr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    lsr = Lasso()\n",
    "    lsr_fitted = lsr.fit(X_train, y_train)\n",
    "    print(\"Lasso fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    lsr_preds = lsr_fitted.predict(X_test)\n",
    "    print(\"Lasso prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, lsr_preds, squared=False))\n",
    "    \n",
    "lsr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-evolution",
   "metadata": {},
   "source": [
    "#### 4. SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "related-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "SGDRegressor fitting time:  24.321774005889893\n",
      "SGDRegressor prediction time:  0.045660972595214844\n",
      "15.822526700949803\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'])\n",
    "def sgdr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    sgdr = SGDRegressor(max_iter=100, penalty='l2')\n",
    "    sgdr_fitted = sgdr.fit(X_train, y_train)\n",
    "    print(\"SGDRegressor fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    sgdr_preds = sgdr_fitted.predict(X_test)\n",
    "    print(\"SGDRegressor prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, sgdr_preds, squared=False))\n",
    "    \n",
    "sgdr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-correspondence",
   "metadata": {},
   "source": [
    "#### 5. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hispanic-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "XGBRegressor fitting time:  443.98497200012207\n",
      "XGBRegressor prediction time:  1.7082109451293945\n",
      "15.822449693847824\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def xgb_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method='approx',\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "    )\n",
    "    xgb_fitted = xgb.fit(X_train, y_train)\n",
    "    print(\"XGBRegressor fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()    \n",
    "    xgb_preds = xgb_fitted.predict(X_test)\n",
    "    print(\"XGBRegressor prediction time: \", time.time() - start)    \n",
    "    print(mean_squared_error(y_test, xgb_preds, squared=False))\n",
    "    \n",
    "xgb_model(X_train, y_train, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-hindu",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
