{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acoustic-camping",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection With Machine Learning in Python\n",
    "\n",
    "This example shows use of classification to help credit card company to detect potential fraud cases using the HPC-like platform Bodo. Credit card data is extracted from Bodo's public S3 bucket, cleaned and processed. Then some analysis are done to extract insight. All are **parallelized across multiple cores using Bodo**. This can be a straightforward way to make Python code run faster without a lot of changes to the code. \n",
    "Original example can be found [here](https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87).\n",
    "\n",
    "You can run the large-scale example on [Bodo platform](https://platform.bodo.ai/account/login).\n",
    "\n",
    "The current results are based on running on 2 `c5.2xlarge` instances (8 cores, 32GiB memory)\n",
    "\n",
    "The dataset was downloaded from Kaggle [here](https://www.kaggle.com/mlg-ulb/creditcardfraud) and save in parquet format in S3 Bucket (`s3://bodo-example-data/creditcard/creditcard.pq/`)\n",
    "The example using CSV dataset can be found in [Bodo-Examples Git repository](https://github.com/Bodo-inc/Bodo-examples/blob/master/ml/credit-card-fraud.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-mongolia",
   "metadata": {},
   "source": [
    "The Bodo framework knows when to parallelize code based on the `%%px` at the start of cells and `@bodo.jit` function decorators. Removing those and restarting the kernel will run the code without Bodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-enzyme",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - Numpy to work with arrays\n",
    " - scikit-learn to build and evaluate classification models\n",
    " - xgboost for xgboost classifier model algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arabic-feeding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:04:42.257135Z",
     "iopub.status.busy": "2022-04-26T23:04:42.256876Z",
     "iopub.status.idle": "2022-04-26T23:04:58.240103Z",
     "shell.execute_reply": "2022-04-26T23:04:58.239705Z",
     "shell.execute_reply.started": "2022-04-26T23:04:42.257111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78402cd9b62e443da13444385ddbfb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cf83f3f6de4f30ab07468f160c968e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/8 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello World from rank 1. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello World from rank 3. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Hello World from rank 7. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello World from rank 2. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Hello World from rank 4. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Hello World from rank 5. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Hello World from rank 6. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello World from rank 0. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bodo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler # data normalization\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm\n",
    "from xgboost import XGBClassifier # XGBoost algorithm\n",
    "from sklearn.svm import LinearSVC # SVM classification algorithm\n",
    "from sklearn.metrics import accuracy_score # evaluation metric\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-daughter",
   "metadata": {},
   "source": [
    "## Data Processing and EDA\n",
    "1. Load dataset\n",
    "2. Compute the percentage of fraud cases in the overall recorded transcations.\n",
    "3. Get a statistical view of both fraud and non-fraud transaction amount data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weighted-being",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:04:58.240954Z",
     "iopub.status.busy": "2022-04-26T23:04:58.240777Z",
     "iopub.status.idle": "2022-04-26T23:05:00.505303Z",
     "shell.execute_reply": "2022-04-26T23:05:00.504912Z",
     "shell.execute_reply.started": "2022-04-26T23:04:58.240935Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1b07a91c3043e5b517740c8a9635d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/8 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Read Time:  2.1310838393079834\n",
       "(284807, 30)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def load_data():\n",
    "    start = time.time()\n",
    "    df = pd.read_parquet('s3://bodo-example-data/creditcard/creditcard.pq')\n",
    "    df.drop('Time', axis = 1, inplace = True)\n",
    "    end = time.time()\n",
    "    print(\"Read Time: \", (end-start))\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-indiana",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:05:04.543652Z",
     "iopub.status.busy": "2022-04-26T23:05:04.543392Z",
     "iopub.status.idle": "2022-04-26T23:05:04.629967Z",
     "shell.execute_reply": "2022-04-26T23:05:04.629585Z",
     "shell.execute_reply.started": "2022-04-26T23:05:04.543631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] --------------------------------------------\n",
       "Total number of cases are  284807\n",
       "Number of Non-fraud cases are  284315\n",
       "Number of fraud cases are 492\n",
       "Percentage of fraud cases is  0.17\n",
       "--------------------------------------------\n",
       "--------------------------------------------\n",
       "NON-FRAUD CASE AMOUNT STATS\n",
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64\n",
       "FRAUD CASE AMOUNT STATS\n",
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64\n",
       "--------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def data_processing(df):\n",
    "    cases = len(df)\n",
    "    nonfraud_cases = df[df.Class == 0]\n",
    "    fraud_cases = df[df.Class == 1]\n",
    "    nonfraud_count = len(nonfraud_cases)\n",
    "    fraud_count = len(fraud_cases)\n",
    "    fraud_percentage = round(fraud_count / nonfraud_count * 100, 2)\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Total number of cases are \", cases)\n",
    "    print(\"Number of Non-fraud cases are \", nonfraud_count)\n",
    "    print(\"Number of fraud cases are\", fraud_count)\n",
    "    print(\"Percentage of fraud cases is \", fraud_percentage)\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"NON-FRAUD CASE AMOUNT STATS\")\n",
    "    print(nonfraud_cases.Amount.describe())\n",
    "    print(\"FRAUD CASE AMOUNT STATS\")\n",
    "    print(fraud_cases.Amount.describe())\n",
    "    print(\"--------------------------------------------\")  \n",
    "\n",
    "data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-mathematics",
   "metadata": {},
   "source": [
    "## Feature Selection & Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-directory",
   "metadata": {},
   "source": [
    "### 1. Normalize `Amount` variable\n",
    "`Amount` variable varies when compared to the rest of the variables. To reduce its range of values, we normalize it using the `StandardScaler` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incomplete-cooling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:05:09.171234Z",
     "iopub.status.busy": "2022-04-26T23:05:09.170960Z",
     "iopub.status.idle": "2022-04-26T23:05:09.352964Z",
     "shell.execute_reply": "2022-04-26T23:05:09.352586Z",
     "shell.execute_reply.started": "2022-04-26T23:05:09.171213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] StandardScaler time:  0.13710344474846892\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.244964\n",
       "1   -0.342475\n",
       "2    1.160686\n",
       "3    0.140534\n",
       "4   -0.073403\n",
       "5   -0.338556\n",
       "6   -0.333279\n",
       "7   -0.190107\n",
       "8    0.019392\n",
       "9   -0.338516\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df'], cache=True)\n",
    "def sc(df):\n",
    "    start = time.time()    \n",
    "    sc = StandardScaler()\n",
    "    amount = df['Amount'].values\n",
    "    amount = amount.reshape(-1,1)\n",
    "    sc.fit(amount)\n",
    "    df['Amount'] = (sc.transform(amount)).ravel()\n",
    "    print(\"StandardScaler time: \", time.time() - start)\n",
    "    return df['Amount'].head(10)\n",
    "\n",
    "sc_df = sc(df)\n",
    "if bodo.get_rank() == 0:\n",
    "    display(sc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-viking",
   "metadata": {},
   "source": [
    "### 2. Split the data into a training set and testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-beauty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:05:12.114768Z",
     "iopub.status.busy": "2022-04-26T23:05:12.114518Z",
     "iopub.status.idle": "2022-04-26T23:05:12.253458Z",
     "shell.execute_reply": "2022-04-26T23:05:12.253075Z",
     "shell.execute_reply.started": "2022-04-26T23:05:12.114748Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] train_test_split time:  0.06754623915503544\n",
       "X_train samples : [[ 1.26585198 -0.1075269   0.47981009 -0.25184768 -0.60788305 -0.52676387\n",
       "  -0.34531619  0.02365571  0.21786475 -0.03118412  1.10872232  0.59520842\n",
       "  -0.28786759  0.38413387  0.61749279  0.71709663 -0.71275056  0.23189477\n",
       "   0.44609545 -0.07168675 -0.10932857 -0.35212209  0.04888506  0.03685774\n",
       "   0.11879204  0.90961715 -0.07721121 -0.00528953 -0.34963112]]\n",
       "X_test samples : [[-0.2500975   0.86416881  1.71780059  0.42077176  0.45859239 -0.57885514\n",
       "   0.94800926 -0.51391496 -0.31043625 -0.02031068  0.55475393  0.09970827\n",
       "   0.43210406 -0.79585124  1.45354931 -0.47625902  0.39926659 -0.69608176\n",
       "   0.13674418  0.14104106 -0.19687718 -0.20118382  0.02023838  0.37742844\n",
       "  -0.90739478  0.02715091 -0.29036732 -0.27941574 -0.33619755]]\n",
       "y_train samples : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
       "y_test samples : [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['df', 'X_train', 'X_test', 'y_train', 'y_test'], cache=True)\n",
    "def data_split(df):\n",
    "    X = df.drop('Class', axis = 1).values\n",
    "    y = df['Class'].values.astype(np.int64)\n",
    "    start = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "    print(\"train_test_split time: \", time.time() - start)    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = data_split(df)\n",
    "if bodo.get_rank() == 0:\n",
    "    print('X_train samples :', X_train[:1])\n",
    "    print('X_test samples :', X_test[0:1])\n",
    "    print('y_train samples :', y_train[0:20])\n",
    "    print('y_test samples :', y_test[0:20])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-antarctica",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Here we have built four different types of classification models and evaluate these models using accuracy score metrics provided by scikit-learn package.\n",
    "\n",
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hidden-baptist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:05:15.739978Z",
     "iopub.status.busy": "2022-04-26T23:05:15.739732Z",
     "iopub.status.idle": "2022-04-26T23:05:16.483427Z",
     "shell.execute_reply": "2022-04-26T23:05:16.483042Z",
     "shell.execute_reply.started": "2022-04-26T23:05:15.739959Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] LogisticRegression fit and predict time:  0.6353843132923984\n",
       "Accuracy score of the Logistic Regression model is 0.9987008883115059\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def lr_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_yhat = lr.predict(X_test)\n",
    "    print(\"LogisticRegression fit and predict time: \", time.time()-start)\n",
    "    print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "    \n",
    "    \n",
    "lr_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-lawrence",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intensive-penny",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:05:19.602287Z",
     "iopub.status.busy": "2022-04-26T23:05:19.602029Z",
     "iopub.status.idle": "2022-04-26T23:05:36.827518Z",
     "shell.execute_reply": "2022-04-26T23:05:36.827140Z",
     "shell.execute_reply.started": "2022-04-26T23:05:19.602266Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dc6b54cf104a84a4bf6f5afb9b2edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/8 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] RandomForestClassifier fit and predict time:  17.153762485349738\n",
       "Accuracy score of the Random Forest Tree model is 0.9988237772550121\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier(max_depth = 4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_yhat = rf.predict(X_test)\n",
    "    print(\"RandomForestClassifier fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "\n",
    "rf_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-stamp",
   "metadata": {},
   "source": [
    "#### 3. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extraordinary-stress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:06:12.728048Z",
     "iopub.status.busy": "2022-04-26T23:06:12.727793Z",
     "iopub.status.idle": "2022-04-26T23:06:18.427124Z",
     "shell.execute_reply": "2022-04-26T23:06:18.426734Z",
     "shell.execute_reply.started": "2022-04-26T23:06:12.728029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64eab3452c247c6b6157c9816c33faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/8 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
       "XGBClassifier fit and predict time:  3.700095154756724\n",
       "Accuracy score of the XGBoost model is 0.9989115550718023\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] [23:06:14] WARNING: /xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def xgb_model(X_train, X_test, y_train, y_test):  \n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(max_depth = 4)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_yhat = xgb.predict(X_test)\n",
    "    print(\"XGBClassifier fit and predict time: \", time.time()-start) \n",
    "    print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
    "\n",
    "xgb_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-jones",
   "metadata": {},
   "source": [
    "#### 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "falling-species",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:06:33.506482Z",
     "iopub.status.busy": "2022-04-26T23:06:33.506219Z",
     "iopub.status.idle": "2022-04-26T23:06:34.195419Z",
     "shell.execute_reply": "2022-04-26T23:06:34.195028Z",
     "shell.execute_reply.started": "2022-04-26T23:06:33.506462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] LinearSVC fit and predict time:  0.4209893488538796\n",
       "Accuracy score of the Linear Support Vector Classification model is 0.9987008883115059\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=['X_train', 'y_train', 'X_test', 'y_test'], cache=True)\n",
    "def lsvc_model(X_train, X_test, y_train, y_test):  \n",
    "    start = time.time()\n",
    "    lsvc = LinearSVC(random_state=42)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    lsvc_yhat = lsvc.predict(X_test)\n",
    "    print(\"LinearSVC fit and predict time: \", time.time()-start) \n",
    "    print('Accuracy score of the Linear Support Vector Classification model is {}'.format(accuracy_score(y_test, lsvc_yhat)))\n",
    "\n",
    "lsvc_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9641a1d-d7bd-4a48-9161-3fd48580f354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "bodo_platform_dummy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
